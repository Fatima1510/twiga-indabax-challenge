{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b68570f",
   "metadata": {},
   "source": [
    "# üéØ Strategy 3: Hybrid Approach (LlamaParse + AI Enhancement)\n",
    "\n",
    "**Philosophy**: Combine the best of both worlds - use LlamaParse's sophisticated parsing capabilities, then enhance with custom AI processing for optimal academic structure.\n",
    "\n",
    "## Optimization Areas:\n",
    "- LlamaParse parameter optimization\n",
    "- AI enhancement prompts\n",
    "- Intelligent result merging\n",
    "- Quality validation and filtering\n",
    "- Multi-stage processing pipeline\n",
    "\n",
    "## Available Papers:\n",
    "- `30YearsResearchGate.pdf`\n",
    "- `SchenkBekkerSchmitt2025PrecRes.pdf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7e80dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: llama_parse in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (0.6.51)\n",
      "Requirement already satisfied: together in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (1.4.6)\n",
      "Requirement already satisfied: pydantic in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (2.11.7)\n",
      "Requirement already satisfied: llama-cloud-services>=0.6.51 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama_parse) (0.6.51)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.8.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from together) (13.9.4)\n",
      "Requirement already satisfied: pyarrow>=10.0.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from together) (21.0.0)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from together) (0.9.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from together) (2.32.4)\n",
      "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from together) (3.18.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from together) (3.12.14)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.1.3 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from together) (0.2.2)\n",
      "Requirement already satisfied: typer<0.16,>=0.9 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from together) (0.15.4)\n",
      "Requirement already satisfied: numpy>=1.23.5 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from together) (2.0.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from together) (4.67.1)\n",
      "Requirement already satisfied: pillow<12.0.0,>=11.1.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from together) (11.3.0)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from together) (8.1.8)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from pydantic) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from pydantic) (4.14.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from pydantic) (0.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.6.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.7.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.20.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (2.6.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (25.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.4.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (0.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (5.0.1)\n",
      "Requirement already satisfied: llama_parse in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (0.6.51)\n",
      "Requirement already satisfied: together in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (1.4.6)\n",
      "Requirement already satisfied: pydantic in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (2.11.7)\n",
      "Requirement already satisfied: llama-cloud-services>=0.6.51 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama_parse) (0.6.51)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.8.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from together) (13.9.4)\n",
      "Requirement already satisfied: pyarrow>=10.0.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from together) (21.0.0)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from together) (0.9.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from together) (2.32.4)\n",
      "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from together) (3.18.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from together) (3.12.14)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.1.3 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from together) (0.2.2)\n",
      "Requirement already satisfied: typer<0.16,>=0.9 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from together) (0.15.4)\n",
      "Requirement already satisfied: numpy>=1.23.5 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from together) (2.0.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from together) (4.67.1)\n",
      "Requirement already satisfied: pillow<12.0.0,>=11.1.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from together) (11.3.0)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from together) (8.1.8)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from pydantic) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from pydantic) (4.14.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from pydantic) (0.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.6.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.7.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.20.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (2.6.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (25.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.4.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (0.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (5.0.1)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud-services>=0.6.51->llama_parse) (1.1.1)\n",
      "Requirement already satisfied: llama-index-core>=0.12.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud-services>=0.6.51->llama_parse) (0.12.52)\n",
      "Requirement already satisfied: tenacity<10.0,>=8.5.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud-services>=0.6.51->llama_parse) (9.1.2)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=4.3.7 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud-services>=0.6.51->llama_parse) (4.3.8)\n",
      "Requirement already satisfied: llama-cloud==0.1.34 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud-services>=0.6.51->llama_parse) (0.1.34)\n",
      "Requirement already satisfied: httpx>=0.20.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud==0.1.34->llama-cloud-services>=0.6.51->llama_parse) (0.28.1)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud==0.1.34->llama-cloud-services>=0.6.51->llama_parse) (2025.7.14)\n",
      "Requirement already satisfied: idna in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from httpx>=0.20.0->llama-cloud==0.1.34->llama-cloud-services>=0.6.51->llama_parse) (3.10)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from httpx>=0.20.0->llama-cloud==0.1.34->llama-cloud-services>=0.6.51->llama_parse) (1.0.9)\n",
      "Requirement already satisfied: anyio in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from httpx>=0.20.0->llama-cloud==0.1.34->llama-cloud-services>=0.6.51->llama_parse) (4.9.0)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx>=0.20.0->llama-cloud==0.1.34->llama-cloud-services>=0.6.51->llama_parse) (0.16.0)\n",
      "Requirement already satisfied: dataclasses-json in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (0.6.7)\n",
      "Requirement already satisfied: banks<3,>=2.2.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (2.2.0)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (2025.7.0)\n",
      "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.1.0)\n",
      "Requirement already satisfied: sqlalchemy[asyncio]>=1.4.49 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (2.0.41)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud-services>=0.6.51->llama_parse) (1.1.1)\n",
      "Requirement already satisfied: llama-index-core>=0.12.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud-services>=0.6.51->llama_parse) (0.12.52)\n",
      "Requirement already satisfied: tenacity<10.0,>=8.5.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud-services>=0.6.51->llama_parse) (9.1.2)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=4.3.7 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud-services>=0.6.51->llama_parse) (4.3.8)\n",
      "Requirement already satisfied: llama-cloud==0.1.34 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud-services>=0.6.51->llama_parse) (0.1.34)\n",
      "Requirement already satisfied: httpx>=0.20.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud==0.1.34->llama-cloud-services>=0.6.51->llama_parse) (0.28.1)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud==0.1.34->llama-cloud-services>=0.6.51->llama_parse) (2025.7.14)\n",
      "Requirement already satisfied: idna in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from httpx>=0.20.0->llama-cloud==0.1.34->llama-cloud-services>=0.6.51->llama_parse) (3.10)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from httpx>=0.20.0->llama-cloud==0.1.34->llama-cloud-services>=0.6.51->llama_parse) (1.0.9)\n",
      "Requirement already satisfied: anyio in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from httpx>=0.20.0->llama-cloud==0.1.34->llama-cloud-services>=0.6.51->llama_parse) (4.9.0)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx>=0.20.0->llama-cloud==0.1.34->llama-cloud-services>=0.6.51->llama_parse) (0.16.0)\n",
      "Requirement already satisfied: dataclasses-json in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (0.6.7)\n",
      "Requirement already satisfied: banks<3,>=2.2.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (2.2.0)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (2025.7.0)\n",
      "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.1.0)\n",
      "Requirement already satisfied: sqlalchemy[asyncio]>=1.4.49 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (2.0.41)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (0.9.0)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (6.0.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (3.9.1)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (0.9.0)\n",
      "Requirement already satisfied: aiosqlite in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (0.21.0)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (80.9.0)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.2.18)\n",
      "Requirement already satisfied: wrapt in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.17.2)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.2.0)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from banks<3,>=2.2.0->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (3.1.6)\n",
      "Requirement already satisfied: griffe in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from banks<3,>=2.2.0->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (0.9.0)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (6.0.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (3.9.1)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (0.9.0)\n",
      "Requirement already satisfied: aiosqlite in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (0.21.0)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (80.9.0)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.2.18)\n",
      "Requirement already satisfied: wrapt in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.17.2)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.2.0)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from banks<3,>=2.2.0->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (3.1.6)\n",
      "Requirement already satisfied: griffe in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from banks<3,>=2.2.0->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.8.0)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (0.3.0)\n",
      "Requirement already satisfied: joblib in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from nltk>3.8.1->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from nltk>3.8.1->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (2024.11.6)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (0.3.0)\n",
      "Requirement already satisfied: joblib in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from nltk>3.8.1->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from nltk>3.8.1->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (2024.11.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.31.0->together) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.31.0->together) (2.5.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from rich<14.0.0,>=13.8.1->together) (2.19.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from rich<14.0.0,>=13.8.1->together) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.8.1->together) (0.1.2)\n",
      "Requirement already satisfied: greenlet>=1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (3.2.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.31.0->together) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.31.0->together) (2.5.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from rich<14.0.0,>=13.8.1->together) (2.19.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from rich<14.0.0,>=13.8.1->together) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.8.1->together) (0.1.2)\n",
      "Requirement already satisfied: greenlet>=1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (3.2.3)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from typer<0.16,>=0.9->together) (1.5.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from typing-inspect>=0.8.0->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.1.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from typer<0.16,>=0.9->together) (1.5.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from typing-inspect>=0.8.0->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from anyio->httpx>=0.20.0->llama-cloud==0.1.34->llama-cloud-services>=0.6.51->llama_parse) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from anyio->httpx>=0.20.0->llama-cloud==0.1.34->llama-cloud-services>=0.6.51->llama_parse) (1.3.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from dataclasses-json->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (25.0)\n",
      "Requirement already satisfied: colorama>=0.4 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from griffe->banks<3,>=2.2.0->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (3.0.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from anyio->httpx>=0.20.0->llama-cloud==0.1.34->llama-cloud-services>=0.6.51->llama_parse) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from anyio->httpx>=0.20.0->llama-cloud==0.1.34->llama-cloud-services>=0.6.51->llama_parse) (1.3.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from dataclasses-json->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (25.0)\n",
      "Requirement already satisfied: colorama>=0.4 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from griffe->banks<3,>=2.2.0->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (3.0.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip3 install llama_parse together pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1537e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_parse import LlamaParse\n",
    "from together import Together\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "import json\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0e7ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Keys\n",
    "api_key = \"llx-xxx\"\n",
    "tog_api = \"xxx\"\n",
    "together = Together(api_key=tog_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b47cd737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö° OPTIMIZATION AREA: Enhanced Data Model\n",
    "class ResearchChunk(BaseModel):\n",
    "    section_type: str = Field(description=\"Type of section: abstract, introduction, methodology, results, discussion, conclusion, references, etc.\")\n",
    "    section_number: Optional[str] = Field(description=\"Section number if available (e.g., '2.1', '3.2')\")\n",
    "    page_number: int = Field(description=\"Page number of the chunk\")\n",
    "    content: str = Field(description=\"Parsed content of the chunk\")\n",
    "    is_figure_caption: bool = Field(default=False, description=\"Whether this chunk is a figure caption\")\n",
    "    is_table: bool = Field(default=False, description=\"Whether this chunk contains table data\")\n",
    "    \n",
    "    # Enhanced fields for hybrid approach\n",
    "    confidence_score: Optional[float] = Field(default=None, description=\"AI confidence in parsing accuracy\")\n",
    "    has_citations: bool = Field(default=False, description=\"Whether chunk contains citations\")\n",
    "    has_equations: bool = Field(default=False, description=\"Whether chunk contains mathematical equations\")\n",
    "    keywords: Optional[list[str]] = Field(default=None, description=\"Key academic terms found in chunk\")\n",
    "    subsection_title: Optional[str] = Field(default=None, description=\"Subsection title if identifiable\")\n",
    "    source_method: Optional[str] = Field(default=None, description=\"Method used to extract this chunk (llamaparse, ai_enhancement, merged)\")\n",
    "\n",
    "class ResearchPaper(BaseModel):\n",
    "    title: Optional[str] = Field(description=\"Title of the research paper if identifiable\")\n",
    "    authors: Optional[str] = Field(description=\"Authors of the paper if identifiable\")\n",
    "    chunks: list[ResearchChunk] = Field(description=\"List of chunks that build the research paper\")\n",
    "    \n",
    "    # Enhanced metadata\n",
    "    abstract: Optional[str] = Field(default=None, description=\"Paper abstract if identifiable\")\n",
    "    publication_year: Optional[int] = Field(default=None, description=\"Publication year if found\")\n",
    "    journal: Optional[str] = Field(default=None, description=\"Journal or venue if identifiable\")\n",
    "    doi: Optional[str] = Field(default=None, description=\"DOI if found in paper\")\n",
    "    total_pages: Optional[int] = Field(default=None, description=\"Total number of pages processed\")\n",
    "    processing_method: Optional[str] = Field(default=None, description=\"Method used for processing (hybrid)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce5e785f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper 1: /Users/fredygerman/Personal/builds/exp/twiga-challenge-1/data/papers/30YearsResearchGate.pdf\n",
      "Paper 2: /Users/fredygerman/Personal/builds/exp/twiga-challenge-1/data/papers/SchenkBekkerSchmitt2025PrecRes.pdf\n"
     ]
    }
   ],
   "source": [
    "# Research paper file paths\n",
    "research_paper_1 = \"/Users/fredygerman/Personal/builds/exp/twiga-challenge-1/data/papers/30YearsResearchGate.pdf\"\n",
    "research_paper_2 = \"/Users/fredygerman/Personal/builds/exp/twiga-challenge-1/data/papers/SchenkBekkerSchmitt2025PrecRes.pdf\"\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"/Users/fredygerman/Personal/builds/exp/twiga-challenge-1/data/input_papers/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Paper 1: {research_paper_1}\")\n",
    "print(f\"Paper 2: {research_paper_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ccc1482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö° OPTIMIZATION AREA 1: Optimized LlamaParse Configuration\n",
    "llamaparse_academic_prompt = \"\"\"\n",
    "The provided document is a research paper. Parse it systematically while preserving academic structure.\n",
    "\n",
    "ACADEMIC PARSING PRIORITIES:\n",
    "1. Identify and preserve section hierarchy (abstract, introduction, methodology, results, discussion, conclusion)\n",
    "2. Maintain figure captions and table data with clear labeling\n",
    "3. Preserve section numbering and subsection structure\n",
    "4. Keep mathematical formulas, equations, and citations intact\n",
    "5. Maintain academic formatting and terminology\n",
    "6. Separate different content types (text, figures, tables, references)\n",
    "7. Preserve page information for reference\n",
    "\n",
    "Output should be well-structured markdown optimized for further AI processing.\n",
    "\"\"\"\n",
    "\n",
    "def stage1_llamaparse(pdf_path: str, temp_output_path: str):\n",
    "    \"\"\"Stage 1: Extract content using optimized LlamaParse\"\"\"\n",
    "    \n",
    "    # ‚ö° OPTIMIZATION AREA: LlamaParse Parameters\n",
    "    parser = LlamaParse(\n",
    "        api_key=api_key,\n",
    "        result_type=\"markdown\",  # üîß TRY: \"text\", \"markdown\" for different formats\n",
    "        system_prompt=llamaparse_academic_prompt,\n",
    "        verbose=True,\n",
    "        # üîß TRY: Experiment with these parameters:\n",
    "        # language=\"en\",\n",
    "        # num_workers=4,\n",
    "        # split_by_page=True,\n",
    "        # use_vendor_multimodal_model=True,\n",
    "    )\n",
    "    \n",
    "    print(f\"Stage 1: LlamaParse processing {pdf_path}\")\n",
    "    parsed_documents = parser.load_data(pdf_path)\n",
    "    \n",
    "    # Save intermediate result\n",
    "    with open(temp_output_path, 'w', encoding='utf-8') as f:\n",
    "        for doc in parsed_documents:\n",
    "            f.write(doc.text + '\\n')\n",
    "    \n",
    "    print(f\"Stage 1 complete: Saved to {temp_output_path}\")\n",
    "    \n",
    "    # Read back the content\n",
    "    with open(temp_output_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "819bc137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö° OPTIMIZATION AREA 2: AI Enhancement Prompts\n",
    "ai_enhancement_prompt = \"\"\"\n",
    "You are processing research paper content that was already parsed by LlamaParse. \n",
    "Enhance the structure by breaking it into precise academic chunks.\n",
    "\n",
    "ENHANCEMENT OBJECTIVES:\n",
    "1. Create granular chunks for each distinct academic element\n",
    "2. Identify and classify section types with high accuracy\n",
    "3. Extract metadata (section numbers, page references)\n",
    "4. Detect and separate figures, tables, and captions\n",
    "5. Preserve citations and mathematical content\n",
    "6. Maintain academic language and terminology\n",
    "\n",
    "CRITICAL JSON FORMATTING:\n",
    "1. Escape all quotes in content with \\\\\"\n",
    "2. Replace newlines in content with \\\\n\n",
    "3. Ensure valid JSON structure\n",
    "4. No trailing commas\n",
    "5. Keep content strings under 1000 characters each\n",
    "\n",
    "CHUNKING REQUIREMENTS:\n",
    "1. Create AT LEAST 20-40 chunks from the provided text\n",
    "2. Each paragraph should be its own chunk\n",
    "3. Each section/subsection should be separate chunks\n",
    "4. Identify section types: abstract, introduction, methodology, results, discussion, conclusion, references\n",
    "5. Extract section numbers (e.g., \"2.1\", \"3.2\") when available\n",
    "6. Mark figure captions and tables separately\n",
    "7. Preserve academic language and citations\n",
    "\n",
    "For each chunk:\n",
    "- section_type: abstract, introduction, methodology, results, discussion, conclusion, references, figure_caption, table, other\n",
    "- section_number: extract from text (e.g., \"2.1\", \"3.2\") or null\n",
    "- page_number: extract from text or estimate\n",
    "- content: the actual text content (PROPERLY ESCAPED and UNDER 1000 chars)\n",
    "- is_figure_caption: true if this is a figure caption\n",
    "- is_table: true if this contains table data\n",
    "- source_method: \"ai_enhancement\"\n",
    "\n",
    "CRITICAL: Do NOT merge paragraphs or sections. Each distinct element = one chunk.\n",
    "\"\"\"\n",
    "\n",
    "def robust_json_parse(ai_response, schema_class):\n",
    "    \"\"\"Robust JSON parsing with multiple fallback strategies\"\"\"\n",
    "    \n",
    "    if not ai_response or not ai_response.choices or len(ai_response.choices) == 0:\n",
    "        raise Exception(\"Invalid AI response: no choices available\")\n",
    "    \n",
    "    raw_content = ai_response.choices[0].message.content\n",
    "    \n",
    "    if not raw_content:\n",
    "        raise Exception(\"Invalid AI response: no content available\")\n",
    "    \n",
    "    # Strategy 1: Direct parsing\n",
    "    try:\n",
    "        return schema_class.model_validate_json(raw_content)\n",
    "    except Exception as e1:\n",
    "        print(f\"Direct parsing failed: {e1}\")\n",
    "    \n",
    "    # Strategy 2: Clean and retry\n",
    "    try:\n",
    "        cleaned = re.sub(r'(?<!\\\\)\"(?![,:}\\]])', r'\\\\\"', raw_content)\n",
    "        cleaned = re.sub(r'(?<!\\\\)\\n(?![,:}\\]])', r'\\\\n', cleaned)\n",
    "        json.loads(cleaned)  # Validate\n",
    "        return schema_class.model_validate_json(cleaned)\n",
    "    except Exception as e2:\n",
    "        print(f\"Cleaning strategy failed: {e2}\")\n",
    "    \n",
    "    # Strategy 3: AI reformat\n",
    "    try:\n",
    "        print(\"üîß Requesting AI to reformat response...\")\n",
    "        reformat_response = together.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"Fix this JSON by properly escaping quotes, removing trailing commas, ensuring valid format. Keep all data intact.\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Fix this JSON:\\n{raw_content[:8000]}\",\n",
    "                },\n",
    "            ],\n",
    "            model=\"meta-llama/Llama-Vision-Free\",\n",
    "            temperature=0.0,\n",
    "            stream=False,\n",
    "        )\n",
    "        \n",
    "        if reformat_response and reformat_response.choices and len(reformat_response.choices) > 0:\n",
    "            reformat_content = reformat_response.choices[0].message.content\n",
    "            if reformat_content:\n",
    "                return schema_class.model_validate_json(reformat_content)\n",
    "    except Exception as e3:\n",
    "        print(f\"AI reformat failed: {e3}\")\n",
    "    \n",
    "    # Strategy 4: Manual fallback\n",
    "    print(\"üîß Using manual fallback...\")\n",
    "    return ResearchPaper(\n",
    "        title=\"Research Paper (Hybrid - Fallback)\",\n",
    "        authors=\"Unknown (parsing error)\",\n",
    "        chunks=[\n",
    "            ResearchChunk(\n",
    "                section_type=\"other\",\n",
    "                page_number=1,\n",
    "                content=\"Failed to parse content. Please check the input format.\",\n",
    "                source_method=\"fallback\"\n",
    "            )\n",
    "        ],\n",
    "        processing_method=\"hybrid\"\n",
    "    )\n",
    "\n",
    "def stage2_ai_enhancement(llamaparse_content: str):\n",
    "    \"\"\"Stage 2: Enhance LlamaParse output with AI structuring\"\"\"\n",
    "    \n",
    "    print(f\"Stage 2: AI enhancement processing ({len(llamaparse_content)} chars)\")\n",
    "    \n",
    "    # ‚ö° OPTIMIZATION AREA: AI Model and Parameters\n",
    "    response = together.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": ai_enhancement_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Enhance this LlamaParse content into structured chunks:\\n\\n{llamaparse_content}\",\n",
    "            },\n",
    "        ],\n",
    "        model=\"meta-llama/Llama-Vision-Free\",  # üîß TRY: Different models\n",
    "        response_format={\"type\": \"json_object\", \"schema\": ResearchPaper.model_json_schema()},\n",
    "        temperature=0.1,  # üîß TRY: Adjust for consistency vs creativity\n",
    "        max_tokens=4000,  # üîß TRY: Adjust based on content length\n",
    "        stream=False,\n",
    "        # üîß TRY: Add other parameters like top_p, frequency_penalty\n",
    "    )\n",
    "    \n",
    "    # Parse response with robust handling\n",
    "    try:\n",
    "        enhanced_data = robust_json_parse(response, ResearchPaper)\n",
    "        print(f\"Stage 2 complete: Generated {len(enhanced_data.chunks)} chunks\")\n",
    "        enhanced_data.processing_method = \"hybrid\"\n",
    "        return enhanced_data\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Stage 2 failed: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33c1cb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö° OPTIMIZATION AREA 3: Intelligent Result Processing and Validation\n",
    "def stage3_quality_enhancement(research_data: ResearchPaper, original_content: str):\n",
    "    \"\"\"Stage 3: Quality enhancement and validation\"\"\"\n",
    "    \n",
    "    if not research_data or not research_data.chunks:\n",
    "        return research_data\n",
    "    \n",
    "    print(f\"Stage 3: Quality enhancement for {len(research_data.chunks)} chunks\")\n",
    "    \n",
    "    enhanced_chunks = []\n",
    "    \n",
    "    for chunk in research_data.chunks:\n",
    "        # ‚ö° OPTIMIZATION AREA: Quality Assessment\n",
    "        # Add confidence scoring, content validation, etc.\n",
    "        \n",
    "        # Basic quality checks\n",
    "        if len(chunk.content.strip()) < 20:  # Skip very short chunks\n",
    "            continue\n",
    "            \n",
    "        # Enhance chunk metadata\n",
    "        enhanced_chunk = chunk.model_copy()\n",
    "        \n",
    "        # Add confidence score based on content quality\n",
    "        confidence = 0.8  # Base confidence\n",
    "        if chunk.section_number:\n",
    "            confidence += 0.1\n",
    "        if chunk.section_type in ['abstract', 'introduction', 'methodology', 'results', 'discussion', 'conclusion']:\n",
    "            confidence += 0.1\n",
    "        enhanced_chunk.confidence_score = min(confidence, 1.0)\n",
    "        \n",
    "        # Detect citations\n",
    "        if '(' in chunk.content and ')' in chunk.content:\n",
    "            enhanced_chunk.has_citations = True\n",
    "            \n",
    "        # Detect equations (basic heuristic)\n",
    "        if any(symbol in chunk.content for symbol in ['=', '‚àë', '‚à´', '‚àÜ', 'Œ±', 'Œ≤', 'Œ≥']):\n",
    "            enhanced_chunk.has_equations = True\n",
    "        \n",
    "        # Extract keywords (basic implementation)\n",
    "        academic_keywords = ['research', 'study', 'analysis', 'method', 'result', 'conclusion', 'data', 'model']\n",
    "        found_keywords = [kw for kw in academic_keywords if kw.lower() in chunk.content.lower()]\n",
    "        if found_keywords:\n",
    "            enhanced_chunk.keywords = found_keywords[:5]  # Limit to 5\n",
    "        \n",
    "        enhanced_chunks.append(enhanced_chunk)\n",
    "    \n",
    "    # Update research paper with enhanced chunks\n",
    "    research_data.chunks = enhanced_chunks\n",
    "    \n",
    "    print(f\"Stage 3 complete: {len(enhanced_chunks)} quality-enhanced chunks\")\n",
    "    return research_data\n",
    "\n",
    "def process_paper_hybrid(pdf_path: str, output_filename: str):\n",
    "    \"\"\"Complete hybrid processing pipeline\"\"\"\n",
    "    \n",
    "    print(f\"\\nüöÄ HYBRID PROCESSING: {pdf_path}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Stage 1: LlamaParse\n",
    "    temp_file = os.path.join(output_dir, f\"temp_{output_filename.replace('.md', '_llamaparse.md')}\")\n",
    "    llamaparse_content = stage1_llamaparse(pdf_path, temp_file)\n",
    "    \n",
    "    # Stage 2: AI Enhancement\n",
    "    enhanced_data = stage2_ai_enhancement(llamaparse_content)\n",
    "    \n",
    "    if not enhanced_data:\n",
    "        print(\"‚ùå Hybrid processing failed\")\n",
    "        return None\n",
    "    \n",
    "    # Stage 3: Quality Enhancement\n",
    "    final_data = stage3_quality_enhancement(enhanced_data, llamaparse_content)\n",
    "    \n",
    "    # Save results\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    save_hybrid_results(final_data, output_path)\n",
    "    \n",
    "    # Cleanup temp file\n",
    "    if os.path.exists(temp_file):\n",
    "        os.remove(temp_file)\n",
    "    \n",
    "    print(f\"\\n‚úÖ HYBRID PROCESSING COMPLETE: {output_path}\")\n",
    "    return final_data\n",
    "\n",
    "def save_hybrid_results(research_data: ResearchPaper, output_path: str):\n",
    "    \"\"\"Save hybrid processing results with enhanced formatting\"\"\"\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"# {research_data.title or 'Research Paper'} (Hybrid Processing)\\n\\n\")\n",
    "        f.write(f\"**Authors:** {research_data.authors or 'Not identified'}\\n\\n\")\n",
    "        f.write(f\"**Processing Method:** {research_data.processing_method}\\n\\n\")\n",
    "        f.write(f\"**Total Chunks:** {len(research_data.chunks)}\\n\\n\")\n",
    "        \n",
    "        if research_data.abstract:\n",
    "            f.write(f\"**Abstract:** {research_data.abstract}\\n\\n\")\n",
    "        \n",
    "        f.write(\"---\\n\\n\")\n",
    "        \n",
    "        for i, chunk in enumerate(research_data.chunks):\n",
    "            f.write(f\"## Chunk {i+1}\\n\\n\")\n",
    "            f.write(f\"- **Section Type:** {chunk.section_type}\\n\")\n",
    "            f.write(f\"- **Section Number:** {chunk.section_number or 'N/A'}\\n\")\n",
    "            f.write(f\"- **Page:** {chunk.page_number}\\n\")\n",
    "            f.write(f\"- **Figure Caption:** {chunk.is_figure_caption}\\n\")\n",
    "            f.write(f\"- **Table:** {chunk.is_table}\\n\")\n",
    "            f.write(f\"- **Confidence:** {chunk.confidence_score or 'N/A'}\\n\")\n",
    "            f.write(f\"- **Has Citations:** {chunk.has_citations}\\n\")\n",
    "            f.write(f\"- **Has Equations:** {chunk.has_equations}\\n\")\n",
    "            if chunk.keywords:\n",
    "                f.write(f\"- **Keywords:** {', '.join(chunk.keywords)}\\n\")\n",
    "            f.write(f\"- **Source Method:** {chunk.source_method or 'hybrid'}\\n\\n\")\n",
    "            f.write(f\"**Content:**\\n{chunk.content}\\n\\n\")\n",
    "            f.write(\"---\\n\\n\")\n",
    "    \n",
    "    print(f\"Saved {len(research_data.chunks)} enhanced chunks to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f27e2efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Paper 1 with Hybrid Strategy...\n",
      "\n",
      "üöÄ HYBRID PROCESSING: /Users/fredygerman/Personal/builds/exp/twiga-challenge-1/data/papers/30YearsResearchGate.pdf\n",
      "============================================================\n",
      "Stage 1: LlamaParse processing /Users/fredygerman/Personal/builds/exp/twiga-challenge-1/data/papers/30YearsResearchGate.pdf\n",
      "Started parsing the file under job_id 93129083-8720-4b13-a601-8f0b761fb9ac\n",
      "Started parsing the file under job_id 93129083-8720-4b13-a601-8f0b761fb9ac\n",
      "Stage 1 complete: Saved to /Users/fredygerman/Personal/builds/exp/twiga-challenge-1/data/input_papers/temp_strategy3_paper1_hybrid_llamaparse.md\n",
      "Stage 2: AI enhancement processing (53349 chars)\n",
      "Stage 1 complete: Saved to /Users/fredygerman/Personal/builds/exp/twiga-challenge-1/data/input_papers/temp_strategy3_paper1_hybrid_llamaparse.md\n",
      "Stage 2: AI enhancement processing (53349 chars)\n"
     ]
    },
    {
     "ename": "APIError",
     "evalue": "Error code: 402 - {\"message\": \"Credit limit exceeded. Please navigate to https://api.together.xyz/settings/billing to add credit or upgrade your plan.\", \"type_\": \"credit_limit\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Process first research paper with hybrid approach\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing Paper 1 with Hybrid Strategy...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m hybrid_data_1 \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_paper_hybrid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresearch_paper_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrategy3_paper1_hybrid.md\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 64\u001b[0m, in \u001b[0;36mprocess_paper_hybrid\u001b[0;34m(pdf_path, output_filename)\u001b[0m\n\u001b[1;32m     61\u001b[0m llamaparse_content \u001b[38;5;241m=\u001b[39m stage1_llamaparse(pdf_path, temp_file)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Stage 2: AI Enhancement\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m enhanced_data \u001b[38;5;241m=\u001b[39m \u001b[43mstage2_ai_enhancement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllamaparse_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m enhanced_data:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚ùå Hybrid processing failed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[28], line 116\u001b[0m, in \u001b[0;36mstage2_ai_enhancement\u001b[0;34m(llamaparse_content)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStage 2: AI enhancement processing (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(llamaparse_content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m chars)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# ‚ö° OPTIMIZATION AREA: AI Model and Parameters\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mtogether\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mai_enhancement_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnhance this LlamaParse content into structured chunks:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mllamaparse_content\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeta-llama/Llama-Vision-Free\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# üîß TRY: Different models\u001b[39;49;00m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjson_object\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mschema\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mResearchPaper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_json_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# üîß TRY: Adjust for consistency vs creativity\u001b[39;49;00m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# üîß TRY: Adjust based on content length\u001b[39;49;00m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# üîß TRY: Add other parameters like top_p, frequency_penalty\u001b[39;49;00m\n\u001b[1;32m    133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Parse response with robust handling\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/together/resources/chat/completions.py:141\u001b[0m, in \u001b[0;36mChatCompletions.create\u001b[0;34m(self, messages, model, max_tokens, stop, temperature, top_p, top_k, repetition_penalty, presence_penalty, frequency_penalty, min_p, logit_bias, seed, stream, logprobs, echo, n, safety_model, response_format, tools, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m requestor \u001b[38;5;241m=\u001b[39m api_requestor\u001b[38;5;241m.\u001b[39mAPIRequestor(\n\u001b[1;32m    113\u001b[0m     client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client,\n\u001b[1;32m    114\u001b[0m )\n\u001b[1;32m    116\u001b[0m parameter_payload \u001b[38;5;241m=\u001b[39m ChatCompletionRequest(\n\u001b[1;32m    117\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    118\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    139\u001b[0m )\u001b[38;5;241m.\u001b[39mmodel_dump(exclude_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 141\u001b[0m response, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTogetherRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameter_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, TogetherResponse)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/together/abstract/api_requestor.py:249\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, options, stream, remaining_retries, request_timeout)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    233\u001b[0m     options: TogetherRequest,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    241\u001b[0m ]:\n\u001b[1;32m    242\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    243\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    244\u001b[0m         remaining_retries\u001b[38;5;241m=\u001b[39mremaining_retries \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretries,\n\u001b[1;32m    245\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    246\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    247\u001b[0m     )\n\u001b[0;32m--> 249\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/together/abstract/api_requestor.py:635\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    633\u001b[0m     content \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 635\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    642\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/together/abstract/api_requestor.py:707\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Handle streaming errors\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 707\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(resp, rcode, stream_error\u001b[38;5;241m=\u001b[39mstream)\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mAPIError\u001b[0m: Error code: 402 - {\"message\": \"Credit limit exceeded. Please navigate to https://api.together.xyz/settings/billing to add credit or upgrade your plan.\", \"type_\": \"credit_limit\"}"
     ]
    }
   ],
   "source": [
    "# Process first research paper with hybrid approach\n",
    "print(\"Processing Paper 1 with Hybrid Strategy...\")\n",
    "hybrid_data_1 = process_paper_hybrid(research_paper_1, \"strategy3_paper1_hybrid.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ed75f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process second research paper with hybrid approach\n",
    "print(\"Processing Paper 2 with Hybrid Strategy...\")\n",
    "hybrid_data_2 = process_paper_hybrid(research_paper_2, \"strategy3_paper2_hybrid.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075ebc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö° OPTIMIZATION AREA 4: Advanced Quality Analysis\n",
    "def analyze_hybrid_results(research_data, paper_name):\n",
    "    \"\"\"Comprehensive analysis of hybrid processing results\"\"\"\n",
    "    \n",
    "    if not research_data or not research_data.chunks:\n",
    "        print(f\"‚ùå No data for {paper_name}\")\n",
    "        return {}\n",
    "    \n",
    "    # Advanced metrics\n",
    "    section_types = {}\n",
    "    confidence_scores = []\n",
    "    figure_count = 0\n",
    "    table_count = 0\n",
    "    citation_chunks = 0\n",
    "    equation_chunks = 0\n",
    "    total_keywords = 0\n",
    "    content_lengths = []\n",
    "    \n",
    "    for chunk in research_data.chunks:\n",
    "        # Basic counts\n",
    "        section_types[chunk.section_type] = section_types.get(chunk.section_type, 0) + 1\n",
    "        content_lengths.append(len(chunk.content))\n",
    "        \n",
    "        # Quality metrics\n",
    "        if chunk.confidence_score:\n",
    "            confidence_scores.append(chunk.confidence_score)\n",
    "        \n",
    "        if chunk.is_figure_caption:\n",
    "            figure_count += 1\n",
    "        if chunk.is_table:\n",
    "            table_count += 1\n",
    "        if chunk.has_citations:\n",
    "            citation_chunks += 1\n",
    "        if chunk.has_equations:\n",
    "            equation_chunks += 1\n",
    "        if chunk.keywords:\n",
    "            total_keywords += len(chunk.keywords)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    avg_confidence = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0\n",
    "    avg_content_length = sum(content_lengths) / len(content_lengths) if content_lengths else 0\n",
    "    \n",
    "    print(f\"\\nüìä HYBRID ANALYSIS FOR {paper_name}:\")\n",
    "    print(f\"Paper Title: {research_data.title}\")\n",
    "    print(f\"Authors: {research_data.authors}\")\n",
    "    print(f\"Processing Method: {research_data.processing_method}\")\n",
    "    print(f\"Total chunks: {len(research_data.chunks)}\")\n",
    "    print(f\"Average confidence: {avg_confidence:.2f}\")\n",
    "    print(f\"Section distribution: {section_types}\")\n",
    "    print(f\"Figures detected: {figure_count}\")\n",
    "    print(f\"Tables detected: {table_count}\")\n",
    "    print(f\"Chunks with citations: {citation_chunks}\")\n",
    "    print(f\"Chunks with equations: {equation_chunks}\")\n",
    "    print(f\"Total keywords found: {total_keywords}\")\n",
    "    print(f\"Average chunk length: {avg_content_length:.0f} characters\")\n",
    "    \n",
    "    return {\n",
    "        'chunks': len(research_data.chunks),\n",
    "        'avg_confidence': avg_confidence,\n",
    "        'sections': section_types,\n",
    "        'figures': figure_count,\n",
    "        'tables': table_count,\n",
    "        'citations': citation_chunks,\n",
    "        'equations': equation_chunks,\n",
    "        'keywords': total_keywords,\n",
    "        'avg_length': avg_content_length\n",
    "    }\n",
    "\n",
    "# Analyze both papers\n",
    "if hybrid_data_1:\n",
    "    results_1 = analyze_hybrid_results(hybrid_data_1, \"Paper 1 (30YearsResearchGate)\")\n",
    "else:\n",
    "    results_1 = {}\n",
    "    \n",
    "if hybrid_data_2:\n",
    "    results_2 = analyze_hybrid_results(hybrid_data_2, \"Paper 2 (SchenkBekkerSchmitt2025)\")\n",
    "else:\n",
    "    results_2 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c66e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ YOUR OPTIMIZATION WORKSPACE\n",
    "# Implement your Strategy 3 optimizations here\n",
    "\n",
    "print(\"üöÄ Strategy 3 Optimization Workspace\")\n",
    "print(\"\\nOptimization Areas for Hybrid Approach:\")\n",
    "print(\"‚òê LlamaParse parameter optimization\")\n",
    "print(\"‚òê AI enhancement prompt refinement\")\n",
    "print(\"‚òê Multi-stage processing pipeline\")\n",
    "print(\"‚òê Intelligent result merging\")\n",
    "print(\"‚òê Quality validation and filtering\")\n",
    "print(\"‚òê Advanced metadata extraction\")\n",
    "\n",
    "# TODO: Add your optimized Hybrid implementation here\n",
    "\n",
    "# Example optimization template:\n",
    "'''\n",
    "# Your optimized hybrid implementation:\n",
    "\n",
    "# Stage 1: Optimized LlamaParse\n",
    "optimized_llamaparse_config = {\n",
    "    \"result_type\": \"YOUR_OPTIMAL_TYPE\",\n",
    "    \"system_prompt\": \"YOUR_OPTIMIZED_LLAMAPARSE_PROMPT\",\n",
    "    \"language\": \"en\",\n",
    "    \"num_workers\": 4,\n",
    "    # Add other optimized parameters\n",
    "}\n",
    "\n",
    "# Stage 2: Enhanced AI Processing\n",
    "def your_enhanced_ai_processing(content):\n",
    "    # Multiple AI passes for different aspects:\n",
    "    # 1. Structure identification\n",
    "    # 2. Content classification\n",
    "    # 3. Metadata extraction\n",
    "    # 4. Quality validation\n",
    "    pass\n",
    "\n",
    "# Stage 3: Intelligent Merging\n",
    "def your_intelligent_merger(llamaparse_result, ai_result):\n",
    "    # Combine results intelligently:\n",
    "    # - Use confidence scores\n",
    "    # - Resolve conflicts\n",
    "    # - Optimize chunk boundaries\n",
    "    pass\n",
    "\n",
    "# Stage 4: Quality Enhancement\n",
    "def your_quality_enhancer(merged_result):\n",
    "    # Final quality improvements:\n",
    "    # - Content validation\n",
    "    # - Metadata enrichment\n",
    "    # - Consistency checks\n",
    "    pass\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9ec7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä STRATEGY 3 RESULTS SUMMARY\n",
    "print(\"üèÜ STRATEGY 3: HYBRID APPROACH RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if results_1:\n",
    "    print(f\"\\nPaper 1 Results:\")\n",
    "    print(f\"  Total Chunks: {results_1['chunks']}\")\n",
    "    print(f\"  Avg Confidence: {results_1['avg_confidence']:.2f}\")\n",
    "    print(f\"  Section Types: {len(results_1['sections'])}\")\n",
    "    print(f\"  Enhanced Features: {results_1['citations']} citations, {results_1['equations']} equations\")\n",
    "    print(f\"  Figures/Tables: {results_1['figures'] + results_1['tables']}\")\n",
    "    print(f\"  Keywords Found: {results_1['keywords']}\")\n",
    "\n",
    "if results_2:\n",
    "    print(f\"\\nPaper 2 Results:\")\n",
    "    print(f\"  Total Chunks: {results_2['chunks']}\")\n",
    "    print(f\"  Avg Confidence: {results_2['avg_confidence']:.2f}\")\n",
    "    print(f\"  Section Types: {len(results_2['sections'])}\")\n",
    "    print(f\"  Enhanced Features: {results_2['citations']} citations, {results_2['equations']} equations\")\n",
    "    print(f\"  Figures/Tables: {results_2['figures'] + results_2['tables']}\")\n",
    "    print(f\"  Keywords Found: {results_2['keywords']}\")\n",
    "\n",
    "print(\"\\nüéØ Hybrid Approach Advantages:\")\n",
    "print(\"‚úÖ Combines LlamaParse accuracy with AI flexibility\")\n",
    "print(\"‚úÖ Multi-stage processing for better quality\")\n",
    "print(\"‚úÖ Enhanced metadata and confidence scoring\")\n",
    "print(\"‚úÖ Robust error handling and fallbacks\")\n",
    "print(\"‚úÖ Quality validation at each stage\")\n",
    "\n",
    "print(\"\\nüéØ Next Steps:\")\n",
    "print(\"1. Review the enhanced chunk files\")\n",
    "print(\"2. Implement your multi-stage optimizations\")\n",
    "print(\"3. Test different model combinations\")\n",
    "print(\"4. Compare with single-method strategies\")\n",
    "print(\"5. Document your hybrid improvements\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
