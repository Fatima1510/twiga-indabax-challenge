# ğŸš€ Twiga AI Challenge: Document Processing & RAG System

## ğŸ¯ Overview

This repository contains two interconnected challenges for building a complete document processing and RAG (Retrieval-Augmented Generation) system for academic research papers.

## ğŸ“ What You'll Build

This project is split into two main challenges:

- **Document Parsing**: Convert academic PDFs into clean, structured markdown, preserving academic sections, citations, and logical hierarchy. This prepares your data for downstream AI tasks.
- **RAG System**: Build a Retrieval-Augmented Generation (RAG) pipeline that uses your parsed documents to answer academic questions with accurate, cited responses.

## ğŸ“ Project Structure

```
twiga-challenge-1/
â”œâ”€â”€ README.md                    # This file - Main overview
â”œâ”€â”€ parsing-challenge/           # Challenge 1: Document Parsing
â”‚   â”œâ”€â”€ README.md                # Parsing challenge documentation
â”‚   â””â”€â”€ strategy1_llamaparse_direct.ipynb
â”œâ”€â”€ rag-challenge/               # Challenge 2: RAG Implementation
â”‚   â”œâ”€â”€ README.md                # RAG challenge documentation
â”‚   â””â”€â”€ strategy1_chromadb_basic.ipynb     RAG
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ papers/                  # Original PDF files
â”‚   â”œâ”€â”€ input_papers/            # Parsed markdown files
â”‚   â””â”€â”€ vector_store/            # Vector database storage
â””â”€â”€ LICENSE
```

## ğŸ† Challenge Progression

### Phase 1: Document Parsing

- **Notebook**: `parsing-challenge/strategy1_llamaparse_direct.ipynb`
- **Goal**: Parse academic PDFs into structured markdown for RAG.

### Phase 2: RAG System

- **Notebook**: `rag-challenge/strategy1_chromadb_basic.ipynb`
- **Goal**: Build a RAG pipeline for question answering over your parsed documents.

## ğŸ› ï¸ Setup & Installation

### Prerequisites

```bash
# Core dependencies
pip3 install llama_parse pypdf together pydantic

# RAG dependencies
pip3 install chromadb sentence-transformers langchain openai
pip3 install faiss-cpu numpy pandas matplotlib
```

### API Keys Required

Create a `.env` file in the project root based on `.env.example`:

## ğŸ® Getting Started

### Phase 1: Document Parsing (Required First)

1. Navigate to `parsing-challenge/`
2. Open `strategy1_llamaparse_direct.ipynb`
3. Set up API keys and dependencies
4. Parse your research paper(s)
5. Validate output quality

### Phase 2: RAG System (After Phase 1)

1. Navigate to `rag-challenge/`
2. Open `strategy1_chromadb_basic.ipynb`
3. Set up API keys and dependencies
4. Use parsed markdown from Phase 1
5. Test with academic questions

## ğŸ“Š Available Research Papers

- **Mobile-Based_Deep_Learning_Models_for_Banana_Disease.pdf** - Deep learning for banana disease detection
- **Examining_the_Awareness_of_Mobile_Money_Users_on_S.pdf** - Mobile money user awareness study
- **Practical Machine Learning_25_05_04_14_32_34.pdf** - Practical machine learning applications

Both papers contain rich academic content including:

- Complex figures and tables
- Mathematical equations
- Extensive citations and references
- Multi-level section hierarchies

## ğŸ… Evaluation Criteria

### Parsing Challenge (Phase 1)

- **Content Accuracy** (25%) - Text extraction quality
- **Structure Preservation** (25%) - Academic section identification
- **Figure/Table Detection** (20%) - Visual element handling
- **Citation Handling** (15%) - Reference preservation
- **Chunk Quality** (15%) - Logical segmentation

### RAG Challenge (Phase 2)

- **Retrieval Accuracy** (30%) - Relevant chunk identification
- **Answer Quality** (25%) - Generated response accuracy
- **Context Preservation** (20%) - Academic context maintenance
- **System Performance** (15%) - Query response time
- **User Experience** (10%) - Interface and usability

## ğŸš¦ Success Metrics

### Phase 1 Completion Criteria:

âœ… Successfully parse all research papers  
âœ… Generate clean, structured markdown output  
âœ… Preserve academic formatting and citations  
âœ… Create logical, RAG-ready text chunks

### Phase 2 Completion Criteria:

âœ… Build functional vector database from parsed content  
âœ… Implement semantic search capabilities  
âœ… Generate accurate, contextual answers  
âœ… Handle complex academic queries effectively

## ğŸ’¡ Tips for Success

### For Parsing Challenge:

- Focus on academic structure preservation
- Test different prompt engineering approaches
- Validate output against source PDFs
- Optimize for downstream RAG usage

### For RAG Challenge:

- Experiment with chunk size and overlap
- Try different embedding models
- Implement query expansion techniques
- Focus on citation preservation in responses

## ğŸ¯ Next Steps

1. **Start with Phase 1**: Open the parsing notebook and process your PDFs
2. **Move to Phase 2**: Open the RAG notebook and build your Q&A system
3. **Test end-to-end** with academic questions

## ğŸ“ Support

- Check individual challenge READMEs for detailed instructions
- Review baseline implementations before optimizing
- Test incrementally and document your findings
- Focus on one challenge at a time for best results

Ready to build the future of academic document processing? Let's go! ğŸš€
