{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fae6ef47",
   "metadata": {},
   "source": [
    "# 🗄️ Strategy 1: Basic ChromaDB RAG\n",
    "\n",
    "**Philosophy**: Build a solid foundation RAG system using ChromaDB for vector storage and semantic search. Focus on clean implementation and effective retrieval.\n",
    "\n",
    "## Core Components:\n",
    "- Document loading and chunking\n",
    "- Embedding generation with sentence-transformers\n",
    "- ChromaDB vector storage\n",
    "- Semantic similarity search\n",
    "- LLM-powered answer generation\n",
    "\n",
    "## Optimization Areas:\n",
    "- Chunk size and overlap strategies\n",
    "- Embedding model selection\n",
    "- Retrieval parameters (k, similarity threshold)\n",
    "- Prompt engineering for Q&A\n",
    "- Citation and source attribution\n",
    "\n",
    "## Input Requirements:\n",
    "You **must** have completed Phase 1 (parsing challenge) and have parsed markdown files in `../data/input_papers/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7108388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: chromadb in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (1.0.15)\n",
      "Requirement already satisfied: sentence-transformers in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (5.0.0)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from chromadb) (1.35.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from chromadb) (5.1.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from chromadb) (0.21.2)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from chromadb) (2.0.2)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from chromadb) (1.4.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from chromadb) (1.35.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from chromadb) (1.35.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from chromadb) (33.1.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from chromadb) (4.25.0)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from chromadb) (1.19.2)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from chromadb) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from chromadb) (4.14.1)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from chromadb) (0.35.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from chromadb) (1.73.1)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from chromadb) (9.1.2)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: build>=1.0.3 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from chromadb) (0.15.4)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from chromadb) (6.0.2)\n",
      "Requirement already satisfied: pydantic>=1.9 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from chromadb) (2.11.7)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from chromadb) (5.4.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from sentence-transformers) (4.53.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from sentence-transformers) (0.33.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: Pillow in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: pyproject_hooks in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from build>=1.0.3->chromadb) (8.7.0)\n",
      "Requirement already satisfied: packaging>=19.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from build>=1.0.3->chromadb) (25.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from build>=1.0.3->chromadb) (2.2.1)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: certifi in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from httpx>=0.27.0->chromadb) (2025.7.14)\n",
      "Requirement already satisfied: idna in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: anyio in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: requests in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
      "Requirement already satisfied: filelock in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from importlib-metadata>=4.6->build>=1.0.3->chromadb) (3.23.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from jsonschema>=4.19.0->chromadb) (0.26.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from kubernetes>=28.1.0->chromadb) (2.40.3)\n",
      "Requirement already satisfied: six>=1.9.0 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (1.15.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: coloredlogs in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: sympy in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: flatbuffers in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.35.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.35.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.35.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.35.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.56b0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.56b0)\n",
      "Requirement already satisfied: distro>=1.5.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: jinja2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: networkx in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: click<8.2,>=8.0.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.2 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (1.97.1)\n",
      "Requirement already satisfied: google-generativeai in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (0.8.5)\n",
      "Requirement already satisfied: python-dotenv in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (1.1.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: sniffio in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from openai) (2.11.7)\n",
      "Collecting google-ai-generativelanguage==0.6.15\n",
      "  Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (2.40.3)\n",
      "Requirement already satisfied: google-api-python-client in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (2.177.0)\n",
      "Requirement already satisfied: google-api-core in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (2.25.1)\n",
      "Requirement already satisfied: protobuf in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from google-api-core->google-generativeai) (2.32.4)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from google-api-core->google-generativeai) (1.73.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from google-api-core->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: certifi in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
      "Installing collected packages: google-ai-generativelanguage\n",
      "  Attempting uninstall: google-ai-generativelanguage\n",
      "    Found existing installation: google-ai-generativelanguage 0.6.18\n",
      "    Uninstalling google-ai-generativelanguage-0.6.18:\n",
      "      Successfully uninstalled google-ai-generativelanguage-0.6.18\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-google-genai 2.1.8 requires google-ai-generativelanguage<0.7.0,>=0.6.18, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\u001b[0m\n",
      "Successfully installed google-ai-generativelanguage-0.6.15\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.2 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (0.3.26)\n",
      "Requirement already satisfied: langchain-openai in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (0.3.28)\n",
      "Requirement already satisfied: langchain-google-genai in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (2.1.8)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from langchain) (0.3.72)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from langchain) (0.4.8)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.86.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from langchain-openai) (1.97.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from langchain-openai) (0.9.0)\n",
      "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18\n",
      "  Using cached google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.5)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.40.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.73.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
      "Requirement already satisfied: packaging>=23.2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (25.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.14.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from langsmith>=0.1.17->langchain) (3.11.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: certifi in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (2025.7.14)\n",
      "Requirement already satisfied: anyio in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: idna in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: sniffio in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Installing collected packages: google-ai-generativelanguage\n",
      "  Attempting uninstall: google-ai-generativelanguage\n",
      "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
      "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
      "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\n",
      "Successfully installed google-ai-generativelanguage-0.6.18\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.2 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (2.0.2)\n",
      "Requirement already satisfied: pandas in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (2.3.1)\n",
      "Requirement already satisfied: matplotlib in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (3.9.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: pillow>=8 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.23.0)\n",
      "Requirement already satisfied: six>=1.5 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.2 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required packages for ChromaDB RAG with multi-LLM support\n",
    "!pip3 install chromadb sentence-transformers\n",
    "!pip3 install openai google-generativeai python-dotenv\n",
    "!pip3 install langchain langchain-openai langchain-google-genai\n",
    "!pip3 install numpy pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9bf3b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fredygerman/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/fredygerman/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LLM imports - Multi-provider support\n",
    "import openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5994c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 RAG CONFIGURATION:\n",
      "Provider: gemini\n",
      "Model: gemini-1.5-flash\n",
      "Embedding: all-MiniLM-L6-v2\n",
      "Chunk size: 500\n",
      "Retrieval K: 5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# ⚙️ CONFIGURATION\n",
    "class RAGConfig:\n",
    "    # Paths\n",
    "    INPUT_DIR = \"../data/input_papers/\"\n",
    "    OUTPUT_DIR = \"../data/vector_store/\"\n",
    "    \n",
    "    # Chunking parameters\n",
    "    CHUNK_SIZE = 500  # 🔧 TRY: 200, 500, 1000, 1500\n",
    "    CHUNK_OVERLAP = 50  # 🔧 TRY: 0, 25, 50, 100\n",
    "    \n",
    "    # Embedding model\n",
    "    EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"  # 🔧 TRY: \"all-mpnet-base-v2\", \"all-distilroberta-v1\"\n",
    "    \n",
    "    # Retrieval parameters\n",
    "    RETRIEVAL_K = 5  # 🔧 TRY: 3, 5, 7, 10\n",
    "    SIMILARITY_THRESHOLD = 0.3  # 🔧 TRY: 0.2, 0.3, 0.4, 0.5\n",
    "    \n",
    "    # LLM settings - Multi-provider support\n",
    "    LLM_PROVIDER = os.getenv('LLM_PROVIDER', 'openai')  # 🔧 OPTIONS: \"openai\", \"gemini\"\n",
    "    LLM_MODEL = os.getenv('LLM_MODEL', 'gpt-3.5-turbo')  # 🔧 OpenAI: \"gpt-4\", \"gpt-3.5-turbo\" | Gemini: \"gemini-pro\", \"gemini-1.5-flash\"\n",
    "    LLM_TEMPERATURE = float(os.getenv('LLM_TEMPERATURE', '0.1'))  # 🔧 TRY: 0.0, 0.1, 0.3\n",
    "    MAX_TOKENS = int(os.getenv('LLM_MAX_TOKENS', '1000'))  # 🔧 TRY: 500, 1000, 2000\n",
    "\n",
    "config = RAGConfig()\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(config.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Display current configuration\n",
    "print(\"🔧 RAG CONFIGURATION:\")\n",
    "print(f\"Provider: {config.LLM_PROVIDER}\")\n",
    "print(f\"Model: {config.LLM_MODEL}\")\n",
    "print(f\"Embedding: {config.EMBEDDING_MODEL}\")\n",
    "print(f\"Chunk size: {config.CHUNK_SIZE}\")\n",
    "print(f\"Retrieval K: {config.RETRIEVAL_K}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71cf0f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents from: ../data/input_papers\n",
      "Found 3 markdown files\n",
      "Loaded: strategy1_examining_the_awareness_of_mobile_money_users_on_s_llamaparse.md (28,458 chars)\n",
      "Loaded: strategy1_practical_machine_learning_25_05_04_14_32_34_llamaparse.md (543,588 chars)\n",
      "Loaded: strategy1_mobile_based_deep_learning_models_for_banana_disease_llamaparse.md (18,055 chars)\n",
      "\n",
      "Processing: strategy1_examining_the_awareness_of_mobile_money_users_on_s_llamaparse\n",
      "Generated 64 chunks\n",
      "\n",
      "Processing: strategy1_practical_machine_learning_25_05_04_14_32_34_llamaparse\n",
      "Generated 1208 chunks\n",
      "\n",
      "Processing: strategy1_mobile_based_deep_learning_models_for_banana_disease_llamaparse\n",
      "Generated 41 chunks\n",
      "\n",
      "Total chunks created: 1313\n"
     ]
    }
   ],
   "source": [
    "# 📄 DOCUMENT LOADING AND PROCESSING\n",
    "class DocumentProcessor:\n",
    "    def __init__(self, config: RAGConfig):\n",
    "        self.config = config\n",
    "        \n",
    "    def load_parsed_documents(self) -> Dict[str, str]:\n",
    "        \"\"\"Load all parsed markdown files from Phase 1\"\"\"\n",
    "        documents = {}\n",
    "        input_path = Path(self.config.INPUT_DIR)\n",
    "        \n",
    "        print(f\"Loading documents from: {input_path}\")\n",
    "        \n",
    "        # Look for all markdown files\n",
    "        md_files = list(input_path.glob(\"*.md\"))\n",
    "        print(f\"Found {len(md_files)} markdown files\")\n",
    "        \n",
    "        for file_path in md_files:\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read()\n",
    "                    documents[file_path.stem] = content\n",
    "                    print(f\"Loaded: {file_path.name} ({len(content):,} chars)\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {file_path}: {e}\")\n",
    "        \n",
    "        return documents\n",
    "    \n",
    "    def chunk_text(self, text: str, filename: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Split text into overlapping chunks with metadata\"\"\"\n",
    "        chunks = []\n",
    "        \n",
    "        # Simple character-based chunking\n",
    "        # 🔧 OPTIMIZATION AREA: Implement smarter chunking strategies\n",
    "        \n",
    "        start = 0\n",
    "        chunk_id = 0\n",
    "        \n",
    "        while start < len(text):\n",
    "            end = start + self.config.CHUNK_SIZE\n",
    "            chunk_text = text[start:end]\n",
    "            \n",
    "            # Try to break at sentence boundary\n",
    "            if end < len(text):\n",
    "                last_period = chunk_text.rfind('.')\n",
    "                last_newline = chunk_text.rfind('\\n')\n",
    "                break_point = max(last_period, last_newline)\n",
    "                \n",
    "                if break_point > start + self.config.CHUNK_SIZE * 0.7:\n",
    "                    chunk_text = text[start:start + break_point + 1]\n",
    "                    end = start + break_point + 1\n",
    "            \n",
    "            # Create chunk with metadata\n",
    "            chunk = {\n",
    "                'id': f\"{filename}_chunk_{chunk_id}\",\n",
    "                'text': chunk_text.strip(),\n",
    "                'source_file': filename,\n",
    "                'chunk_index': chunk_id,\n",
    "                'start_char': start,\n",
    "                'end_char': end\n",
    "            }\n",
    "            \n",
    "            chunks.append(chunk)\n",
    "            \n",
    "            # Move to next chunk with overlap\n",
    "            start = end - self.config.CHUNK_OVERLAP\n",
    "            chunk_id += 1\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    def process_all_documents(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Process all documents into chunks\"\"\"\n",
    "        documents = self.load_parsed_documents()\n",
    "        all_chunks = []\n",
    "        \n",
    "        for filename, content in documents.items():\n",
    "            print(f\"\\nProcessing: {filename}\")\n",
    "            chunks = self.chunk_text(content, filename)\n",
    "            all_chunks.extend(chunks)\n",
    "            print(f\"Generated {len(chunks)} chunks\")\n",
    "        \n",
    "        print(f\"\\nTotal chunks created: {len(all_chunks)}\")\n",
    "        return all_chunks\n",
    "\n",
    "# Test document processing\n",
    "processor = DocumentProcessor(config)\n",
    "chunks = processor.process_all_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f253fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ChromaDB...\n",
      "ChromaDB storage path: ../data/vector_store/chromadb\n",
      "Created new collection: research_papers\n",
      "Generating embeddings for 1313 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 42/42 [00:05<00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing in ChromaDB...\n",
      "Successfully stored 1313 chunks in ChromaDB\n"
     ]
    }
   ],
   "source": [
    "# 🔍 EMBEDDING AND VECTOR STORAGE\n",
    "class ChromaDBRAG:\n",
    "    def __init__(self, config: RAGConfig):\n",
    "        self.config = config\n",
    "        self.embedding_model = SentenceTransformer(config.EMBEDDING_MODEL)\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        \n",
    "    def initialize_chromadb(self):\n",
    "        \"\"\"Initialize ChromaDB client and collection\"\"\"\n",
    "        print(\"Initializing ChromaDB...\")\n",
    "        \n",
    "        # Ensure the chromadb directory exists and is writable\n",
    "        chroma_dir = os.path.join(self.config.OUTPUT_DIR, \"chromadb\")\n",
    "        os.makedirs(chroma_dir, exist_ok=True)\n",
    "        if not os.access(chroma_dir, os.W_OK):\n",
    "            raise PermissionError(f\"ChromaDB directory is not writable: {chroma_dir}\")\n",
    "        print(f\"ChromaDB storage path: {chroma_dir}\")\n",
    "        \n",
    "        # Create persistent client\n",
    "        self.client = chromadb.PersistentClient(\n",
    "            path=chroma_dir\n",
    "        )\n",
    "        \n",
    "        # Create or get collection\n",
    "        collection_name = \"research_papers\"\n",
    "        try:\n",
    "            self.collection = self.client.get_collection(collection_name)\n",
    "            print(f\"Found existing collection: {collection_name}\")\n",
    "        except Exception:\n",
    "            self.collection = self.client.create_collection(\n",
    "                name=collection_name,\n",
    "                metadata={\"hnsw:space\": \"cosine\"}  # Use cosine similarity\n",
    "            )\n",
    "            print(f\"Created new collection: {collection_name}\")\n",
    "    \n",
    "    def embed_and_store_chunks(self, chunks: List[Dict[str, Any]]):\n",
    "        \"\"\"Generate embeddings and store in ChromaDB\"\"\"\n",
    "        if not self.collection:\n",
    "            self.initialize_chromadb()\n",
    "        \n",
    "        print(f\"Generating embeddings for {len(chunks)} chunks...\")\n",
    "        \n",
    "        # Extract text for embedding\n",
    "        texts = [chunk['text'] for chunk in chunks]\n",
    "        ids = [chunk['id'] for chunk in chunks]\n",
    "        \n",
    "        # Generate embeddings\n",
    "        embeddings = self.embedding_model.encode(\n",
    "            texts, \n",
    "            show_progress_bar=True,\n",
    "            convert_to_numpy=True\n",
    "        )\n",
    "        \n",
    "        # Prepare metadata\n",
    "        metadatas = []\n",
    "        for chunk in chunks:\n",
    "            metadata = {\n",
    "                'source_file': chunk['source_file'],\n",
    "                'chunk_index': chunk['chunk_index'],\n",
    "                'start_char': chunk['start_char'],\n",
    "                'end_char': chunk['end_char']\n",
    "            }\n",
    "            metadatas.append(metadata)\n",
    "        \n",
    "        # Store in ChromaDB\n",
    "        print(\"Storing in ChromaDB...\")\n",
    "        self.collection.add(\n",
    "            ids=ids,\n",
    "            documents=texts,\n",
    "            embeddings=embeddings.tolist(),\n",
    "            metadatas=metadatas\n",
    "        )\n",
    "        \n",
    "        print(f\"Successfully stored {len(chunks)} chunks in ChromaDB\")\n",
    "    \n",
    "    def search_similar_chunks(self, query: str, k: Optional[int] = None) -> Dict[str, Any]:\n",
    "        \"\"\"Search for similar chunks using semantic similarity\"\"\"\n",
    "        if not self.collection:\n",
    "            raise ValueError(\"ChromaDB not initialized. Call initialize_chromadb() first.\")\n",
    "        \n",
    "        k = k or self.config.RETRIEVAL_K\n",
    "        \n",
    "        # Generate query embedding\n",
    "        query_embedding = self.embedding_model.encode([query])\n",
    "        \n",
    "        # Search in ChromaDB\n",
    "        results = self.collection.query(\n",
    "            query_embeddings=query_embedding.tolist(),\n",
    "            n_results=k\n",
    "        )\n",
    "        \n",
    "        # Format results\n",
    "        retrieved_chunks = []\n",
    "        for i in range(len(results['ids'][0])):\n",
    "            chunk = {\n",
    "                'id': results['ids'][0][i],\n",
    "                'text': results['documents'][0][i],\n",
    "                'metadata': results['metadatas'][0][i],\n",
    "                'distance': results['distances'][0][i]\n",
    "            }\n",
    "            retrieved_chunks.append(chunk)\n",
    "        \n",
    "        return {\n",
    "            'query': query,\n",
    "            'retrieved_chunks': retrieved_chunks,\n",
    "            'total_found': len(retrieved_chunks)\n",
    "        }\n",
    "\n",
    "# Initialize RAG system\n",
    "rag_system = ChromaDBRAG(config)\n",
    "rag_system.embed_and_store_chunks(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf54d308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized Gemini LLM: gemini-1.5-flash\n"
     ]
    }
   ],
   "source": [
    "# 🤖 ANSWER GENERATION\n",
    "from pydantic import SecretStr\n",
    "\n",
    "class AnswerGenerator:\n",
    "    def __init__(self, config: RAGConfig):\n",
    "        self.config = config\n",
    "        self.llm = None\n",
    "        self.setup_llm()\n",
    "    \n",
    "    def setup_llm(self):\n",
    "        \"\"\"Initialize the language model\"\"\"\n",
    "        if self.config.LLM_PROVIDER == \"openai\":\n",
    "            api_key = os.getenv('OPENAI_API_KEY')\n",
    "            if not api_key:\n",
    "                print(\"Warning: OPENAI_API_KEY not found. Please set it in your .env file\")\n",
    "                return\n",
    "            self.llm = ChatOpenAI(\n",
    "                model=self.config.LLM_MODEL,\n",
    "                temperature=self.config.LLM_TEMPERATURE,\n",
    "                api_key=SecretStr(api_key)\n",
    "            )\n",
    "            print(f\"Initialized OpenAI LLM: {self.config.LLM_MODEL}\")\n",
    "        elif self.config.LLM_PROVIDER == \"gemini\":\n",
    "            api_key = os.getenv('GEMINI_API_KEY')\n",
    "            if not api_key:\n",
    "                print(\"Warning: GEMINI_API_KEY not found. Please set it in your .env file\")\n",
    "                return\n",
    "            self.llm = ChatGoogleGenerativeAI(\n",
    "                model=self.config.LLM_MODEL,\n",
    "                temperature=self.config.LLM_TEMPERATURE,\n",
    "                max_tokens=self.config.MAX_TOKENS,\n",
    "                google_api_key=api_key\n",
    "            )\n",
    "            print(f\"Initialized Gemini LLM: {self.config.LLM_MODEL}\")\n",
    "        elif self.config.LLM_PROVIDER == \"anthropic\":\n",
    "            api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "            if not api_key:\n",
    "                print(\"Warning: ANTHROPIC_API_KEY not found. Please set it in your .env file\")\n",
    "                return\n",
    "            try:\n",
    "                from langchain_anthropic import ChatAnthropic\n",
    "            except ImportError:\n",
    "                print(\"langchain-anthropic is not installed. Please install it to use Anthropic provider.\")\n",
    "                return\n",
    "            self.llm = ChatAnthropic(\n",
    "                model_name=self.config.LLM_MODEL,\n",
    "                temperature=self.config.LLM_TEMPERATURE,\n",
    "                api_key=SecretStr(api_key),\n",
    "                timeout=30,  # Optional timeout setting\n",
    "                stop=None    # You can set this to a list of stop sequences if needed\n",
    "            )\n",
    "            print(f\"Initialized Anthropic LLM: {self.config.LLM_MODEL}\")\n",
    "        else:\n",
    "            print(f\"Warning: Unknown LLM_PROVIDER '{self.config.LLM_PROVIDER}'. Supported: 'openai', 'gemini', 'anthropic'.\")\n",
    "            return\n",
    "    \n",
    "    def create_system_prompt(self) -> str:\n",
    "        \"\"\"Create system prompt for academic Q&A\"\"\"\n",
    "        return \"\"\"You are an expert academic research assistant. Your task is to answer questions about research papers based on the provided context.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Answer questions accurately based ONLY on the provided context\n",
    "2. If the context doesn't contain enough information, say so clearly\n",
    "3. Always cite your sources by mentioning the source file name\n",
    "4. Maintain academic tone and precision\n",
    "5. Include relevant quotes when appropriate\n",
    "6. If asked about specific details (numbers, dates, names), be precise\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "- Provide a clear, comprehensive answer\n",
    "- Include citations: [Source: filename]\n",
    "- Quote relevant passages when helpful\n",
    "- End with a confidence assessment if uncertain\"\"\"\n",
    "    \n",
    "    def generate_answer(self, query: str, retrieved_chunks: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        \"\"\"Generate answer using retrieved context\"\"\"\n",
    "        if not self.llm:\n",
    "            return {\n",
    "                'answer': 'Error: LLM not properly initialized. Please check your API key.',\n",
    "                'sources': [],\n",
    "                'error': 'LLM initialization failed'\n",
    "            }\n",
    "        \n",
    "        # Prepare context from retrieved chunks\n",
    "        context_parts = []\n",
    "        sources = set()\n",
    "        \n",
    "        for i, chunk in enumerate(retrieved_chunks):\n",
    "            source_file = chunk['metadata']['source_file']\n",
    "            sources.add(source_file)\n",
    "            context_parts.append(f\"Context {i+1} [Source: {source_file}]:\\n{chunk['text']}\\n\")\n",
    "        \n",
    "        context = \"\\n\".join(context_parts)\n",
    "        \n",
    "        # Create prompt\n",
    "        user_prompt = f\"\"\"CONTEXT:\n",
    "{context}\n",
    "\n",
    "QUESTION: {query}\n",
    "\n",
    "Please answer the question based on the provided context.\"\"\"\n",
    "        \n",
    "        try:\n",
    "            # Generate response\n",
    "            messages = [\n",
    "                SystemMessage(content=self.create_system_prompt()),\n",
    "                HumanMessage(content=user_prompt)\n",
    "            ]\n",
    "            \n",
    "            response = self.llm.invoke(messages)\n",
    "            \n",
    "            return {\n",
    "                'answer': response.content,\n",
    "                'sources': list(sources),\n",
    "                'context_used': len(retrieved_chunks),\n",
    "                'query': query\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'answer': f'Error generating answer: {str(e)}',\n",
    "                'sources': [],\n",
    "                'error': str(e)\n",
    "            }\n",
    "\n",
    "# Initialize answer generator\n",
    "answer_generator = AnswerGenerator(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b1e6fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized Gemini LLM: gemini-1.5-flash\n",
      "Initializing ChromaDB...\n",
      "ChromaDB storage path: ../data/vector_store/chromadb\n",
      "Found existing collection: research_papers\n"
     ]
    }
   ],
   "source": [
    "# 🎯 COMPLETE RAG PIPELINE\n",
    "class RAGPipeline:\n",
    "    def __init__(self, config: RAGConfig):\n",
    "        self.config = config\n",
    "        self.rag_system = ChromaDBRAG(config)\n",
    "        self.answer_generator = AnswerGenerator(config)\n",
    "        \n",
    "        # Initialize ChromaDB\n",
    "        self.rag_system.initialize_chromadb()\n",
    "    \n",
    "    def ask_question(self, query: str, k: Optional[int] = None) -> Dict[str, Any]:\n",
    "        \"\"\"Complete RAG pipeline: retrieve + generate\"\"\"\n",
    "        print(f\"\\n🔍 Query: {query}\")\n",
    "        \n",
    "        # Step 1: Retrieve relevant chunks\n",
    "        start_time = time.time()\n",
    "        search_results = self.rag_system.search_similar_chunks(query, k)\n",
    "        retrieval_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"Retrieved {len(search_results['retrieved_chunks'])} chunks in {retrieval_time:.2f}s\")\n",
    "        \n",
    "        # Step 2: Generate answer\n",
    "        start_time = time.time()\n",
    "        answer_result = self.answer_generator.generate_answer(\n",
    "            query, \n",
    "            search_results['retrieved_chunks']\n",
    "        )\n",
    "        generation_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"Generated answer in {generation_time:.2f}s\")\n",
    "        \n",
    "        # Combine results\n",
    "        result = {\n",
    "            'query': query,\n",
    "            'answer': answer_result['answer'],\n",
    "            'sources': answer_result['sources'],\n",
    "            'retrieved_chunks': search_results['retrieved_chunks'],\n",
    "            'performance': {\n",
    "                'retrieval_time': retrieval_time,\n",
    "                'generation_time': generation_time,\n",
    "                'total_time': retrieval_time + generation_time,\n",
    "                'chunks_retrieved': len(search_results['retrieved_chunks'])\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def display_result(self, result: Dict[str, Any]):\n",
    "        \"\"\"Display RAG result in a nice format\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"🤖 ANSWER:\")\n",
    "        print(\"-\" * 30)\n",
    "        print(result['answer'])\n",
    "        \n",
    "        print(f\"\\n📚 SOURCES: {', '.join(result['sources'])}\")\n",
    "        \n",
    "        print(f\"\\n⚡ PERFORMANCE:\")\n",
    "        perf = result['performance']\n",
    "        print(f\"  Retrieval: {perf['retrieval_time']:.2f}s\")\n",
    "        print(f\"  Generation: {perf['generation_time']:.2f}s\") \n",
    "        print(f\"  Total: {perf['total_time']:.2f}s\")\n",
    "        print(f\"  Chunks used: {perf['chunks_retrieved']}\")\n",
    "        \n",
    "        print(\"\\n🔍 RETRIEVED CONTEXT:\")\n",
    "        for i, chunk in enumerate(result['retrieved_chunks'][:3]):  # Show top 3\n",
    "            print(f\"\\n  Chunk {i+1} [Distance: {chunk['distance']:.3f}]:\")\n",
    "            print(f\"  Source: {chunk['metadata']['source_file']}\")\n",
    "            print(f\"  Text: {chunk['text'][:200]}...\")\n",
    "\n",
    "# Initialize complete RAG pipeline\n",
    "rag_pipeline = RAGPipeline(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bb1abc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 TESTING RAG SYSTEM WITH SAMPLE QUESTIONS\n",
      "============================================================\n",
      "\n",
      "🔍 Query: What are the main banana diseases addressed in the paper?\n",
      "Retrieved 5 chunks in 0.12s\n",
      "Generated answer in 91.75s\n",
      "\n",
      "============================================================\n",
      "🤖 ANSWER:\n",
      "------------------------------\n",
      "The provided text mentions Fusarium wilt race 1 and black Sigatoka as major fungal diseases affecting banana yield [Source: strategy1_mobile_based_deep_learning_models_for_banana_disease_llamaparse].  The research specifically focuses on Fusarium wilt in the context of agroforestry systems [Source: strategy1_mobile_based_deep_learning_models_for_banana_disease_llamaparse].\n",
      "\n",
      "📚 SOURCES: strategy1_mobile_based_deep_learning_models_for_banana_disease_llamaparse\n",
      "\n",
      "⚡ PERFORMANCE:\n",
      "  Retrieval: 0.12s\n",
      "  Generation: 91.75s\n",
      "  Total: 91.87s\n",
      "  Chunks used: 5\n",
      "\n",
      "🔍 RETRIEVED CONTEXT:\n",
      "\n",
      "  Chunk 1 [Distance: 0.379]:\n",
      "  Source: strategy1_mobile_based_deep_learning_models_for_banana_disease_llamaparse\n",
      "  Text: ing, and disease incidence was recorded in banana plants.\n",
      "\n",
      "### 2.3 Statistical Analysis\n",
      "Data were analyzed using [Statistical Software], employing ANOVA to determine the significance of soil character...\n",
      "\n",
      "  Chunk 2 [Distance: 0.379]:\n",
      "  Source: strategy1_mobile_based_deep_learning_models_for_banana_disease_llamaparse\n",
      "  Text: ro regions. However, the yield is highly affected by fungal diseases that include Fusarium wilt race 1 and black Sigatoka, resulting in high losses in crop (Deltour et al., 2017; Chillet et al., 2009;...\n",
      "\n",
      "  Chunk 3 [Distance: 0.423]:\n",
      "  Source: strategy1_mobile_based_deep_learning_models_for_banana_disease_llamaparse\n",
      "  Text: reira, O. L., Cardoso, I., De Neve, S., Debode, J., &#x26; Hoefte, M. (2017). Disease suppressiveness to fusarium wilt of banana in an agroforestry system: influence of soil characteristics and plant ...\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "🔍 Query: What deep learning models were used for banana disease detection?\n",
      "Retrieved 5 chunks in 0.39s\n",
      "Generated answer in 12.06s\n",
      "\n",
      "============================================================\n",
      "🤖 ANSWER:\n",
      "------------------------------\n",
      "The study used ResNet152 and InceptionV3 Convolution Neural Network architectures.  ResNet152 achieved an accuracy of 99.2%. [Source: strategy1_mobile_based_deep_learning_models_for_banana_disease_llamaparse]\n",
      "\n",
      "📚 SOURCES: strategy1_mobile_based_deep_learning_models_for_banana_disease_llamaparse\n",
      "\n",
      "⚡ PERFORMANCE:\n",
      "  Retrieval: 0.39s\n",
      "  Generation: 12.06s\n",
      "  Total: 12.45s\n",
      "  Chunks used: 5\n",
      "\n",
      "🔍 RETRIEVED CONTEXT:\n",
      "\n",
      "  Chunk 1 [Distance: 0.182]:\n",
      "  Source: strategy1_mobile_based_deep_learning_models_for_banana_disease_llamaparse\n",
      "  Text: Abstract\n",
      "This paper presents the application of deep learning models for the detection of banana fungal diseases using banana leaf images. We explore the materials and methods used to train and test s...\n",
      "\n",
      "  Chunk 2 [Distance: 0.188]:\n",
      "  Source: strategy1_mobile_based_deep_learning_models_for_banana_disease_llamaparse\n",
      "  Text: # Mobile-Based Deep Learning Models for Banana Diseases Detection\n",
      "\n",
      "**Sophia Sanga, Victor Mero &#x26; Dina Machuve**\n",
      "School of Computational and Communication Sciences and Engineering\n",
      "Nelson Mandela A...\n",
      "\n",
      "  Chunk 3 [Distance: 0.191]:\n",
      "  Source: strategy1_mobile_based_deep_learning_models_for_banana_disease_llamaparse\n",
      "  Text: # 5. Conclusion\n",
      "The conclusion summarizes the findings and suggests future directions for research in the field of banana disease detection using deep learning techniques.\n",
      "\n",
      "## References\n",
      "- Abadi, M., ...\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "✅ Completed testing 2 questions\n"
     ]
    }
   ],
   "source": [
    "# 🧪 TESTING WITH SAMPLE QUESTIONS\n",
    "\n",
    "# Sample academic questions to test the system (specific to the banana disease paper)\n",
    "test_questions = [\n",
    "    \"What are the main banana diseases addressed in the paper?\",\n",
    "    \"What deep learning models were used for banana disease detection?\",\n",
    "    \"How was the dataset for training and testing prepared?\",\n",
    "    \"What were the key results and accuracy metrics for each model?\",\n",
    "    \"Why was InceptionV3 chosen for mobile deployment?\",\n",
    "    \"What are the main conclusions of the study?\",\n",
    "    \"How does agroforestry influence disease suppressiveness in bananas?\",\n",
    "    \"What are the main recommendations for smallholder farmers?\",\n",
    "    \"List the main references cited in the paper.\",\n",
    "    \"What are the limitations and future research directions discussed?\"\n",
    "]\n",
    "\n",
    "print(\"🧪 TESTING RAG SYSTEM WITH SAMPLE QUESTIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test each question\n",
    "test_results = []\n",
    "\n",
    "for question in test_questions[:2]:  # Test first 2 questions\n",
    "    try:\n",
    "        result = rag_pipeline.ask_question(question)\n",
    "        rag_pipeline.display_result(result)\n",
    "        test_results.append(result)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error with question '{question}': {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*60 + \"\\n\")\n",
    "\n",
    "print(f\"✅ Completed testing {len(test_results)} questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e46c242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Strategy 1 ChromaDB RAG Optimization Workspace\n",
      "============================================================\n",
      "\n",
      "🔧 OPTIMIZATION AREAS:\n",
      "☐ Chunk size and overlap tuning\n",
      "☐ Embedding model comparison\n",
      "☐ Retrieval parameter optimization\n",
      "☐ Prompt engineering for academic Q&A\n",
      "☐ Post-processing and citation enhancement\n",
      "☐ Query expansion and rephrasing\n",
      "\n",
      "💡 QUICK OPTIMIZATION IDEAS:\n",
      "\n",
      "1. CHUNKING STRATEGIES:\n",
      "   - Semantic chunking (sentence boundaries)\n",
      "   - Section-based chunking (headers)\n",
      "   - Hierarchical chunking (multi-level)\n",
      "\n",
      "2. EMBEDDING IMPROVEMENTS:\n",
      "   - Try: all-mpnet-base-v2 (better accuracy)\n",
      "   - Try: all-distilroberta-v1 (speed)\n",
      "   - Domain-specific embedding models\n",
      "\n",
      "3. RETRIEVAL ENHANCEMENTS:\n",
      "   - Increase k for more context\n",
      "   - Add metadata filtering\n",
      "   - Implement re-ranking\n",
      "\n",
      "4. GENERATION IMPROVEMENTS:\n",
      "   - Better system prompts\n",
      "   - Chain-of-thought reasoning\n",
      "   - Citation format standardization\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Your optimization implementation space:\\n\\n# Option 1: Better chunking\\ndef semantic_chunk_text(text: str, max_chunk_size: int = 500):\\n    \"\"\"Implement semantic chunking based on sentences/paragraphs\"\"\"\\n    # Your implementation here\\n    pass\\n\\n# Option 2: Enhanced retrieval\\ndef enhanced_search(query: str, k: int = 5):\\n    \"\"\"Add query expansion and better search\"\"\"\\n    # Your implementation here\\n    pass\\n\\n# Option 3: Better prompts\\ndef create_enhanced_prompt():\\n    \"\"\"Improve system prompt for academic Q&A\"\"\"\\n    # Your implementation here\\n    pass\\n\\n# Test your optimizations:\\n# optimized_result = your_enhanced_pipeline.ask_question(\"test question\")\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ⚡ OPTIMIZATION WORKSPACE - Strategy 1\n",
    "print(\"🚀 Strategy 1 ChromaDB RAG Optimization Workspace\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n🔧 OPTIMIZATION AREAS:\")\n",
    "print(\"☐ Chunk size and overlap tuning\")\n",
    "print(\"☐ Embedding model comparison\") \n",
    "print(\"☐ Retrieval parameter optimization\")\n",
    "print(\"☐ Prompt engineering for academic Q&A\")\n",
    "print(\"☐ Post-processing and citation enhancement\")\n",
    "print(\"☐ Query expansion and rephrasing\")\n",
    "\n",
    "print(\"\\n💡 QUICK OPTIMIZATION IDEAS:\")\n",
    "print(\"\\n1. CHUNKING STRATEGIES:\")\n",
    "print(\"   - Semantic chunking (sentence boundaries)\")\n",
    "print(\"   - Section-based chunking (headers)\")\n",
    "print(\"   - Hierarchical chunking (multi-level)\")\n",
    "\n",
    "print(\"\\n2. EMBEDDING IMPROVEMENTS:\")\n",
    "print(\"   - Try: all-mpnet-base-v2 (better accuracy)\")\n",
    "print(\"   - Try: all-distilroberta-v1 (speed)\")\n",
    "print(\"   - Domain-specific embedding models\")\n",
    "\n",
    "print(\"\\n3. RETRIEVAL ENHANCEMENTS:\")\n",
    "print(\"   - Increase k for more context\")\n",
    "print(\"   - Add metadata filtering\")\n",
    "print(\"   - Implement re-ranking\")\n",
    "\n",
    "print(\"\\n4. GENERATION IMPROVEMENTS:\")\n",
    "print(\"   - Better system prompts\")\n",
    "print(\"   - Chain-of-thought reasoning\")\n",
    "print(\"   - Citation format standardization\")\n",
    "\n",
    "# TODO: Implement your optimizations here\n",
    "'''\n",
    "# Your optimization implementation space:\n",
    "\n",
    "# Option 1: Better chunking\n",
    "def semantic_chunk_text(text: str, max_chunk_size: int = 500):\n",
    "    \"\"\"Implement semantic chunking based on sentences/paragraphs\"\"\"\n",
    "    # Your implementation here\n",
    "    pass\n",
    "\n",
    "# Option 2: Enhanced retrieval\n",
    "def enhanced_search(query: str, k: int = 5):\n",
    "    \"\"\"Add query expansion and better search\"\"\"\n",
    "    # Your implementation here\n",
    "    pass\n",
    "\n",
    "# Option 3: Better prompts\n",
    "def create_enhanced_prompt():\n",
    "    \"\"\"Improve system prompt for academic Q&A\"\"\"\n",
    "    # Your implementation here\n",
    "    pass\n",
    "\n",
    "# Test your optimizations:\n",
    "# optimized_result = your_enhanced_pipeline.ask_question(\"test question\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ad07230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 RAG PERFORMANCE ANALYSIS\n",
      "==================================================\n",
      "\n",
      "⏱️ TIMING METRICS:\n",
      "Average retrieval time: 0.25s\n",
      "Average generation time: 51.90s\n",
      "Average total time: 52.16s\n",
      "\n",
      "📚 SOURCE COVERAGE:\n",
      "Unique sources used: 1\n",
      "Sources: strategy1_mobile_based_deep_learning_models_for_banana_disease_llamaparse\n",
      "\n",
      "🔍 RETRIEVAL METRICS:\n",
      "Average chunks per query: 5.0\n",
      "Retrieval consistency: 0.0 std dev\n",
      "\n",
      "📝 ANSWER METRICS:\n",
      "Average answer length: 292 chars\n",
      "Answer length range: 208-375 chars\n"
     ]
    }
   ],
   "source": [
    "# 📊 PERFORMANCE ANALYSIS\n",
    "def analyze_rag_performance(test_results: List[Dict[str, Any]]):\n",
    "    \"\"\"Analyze RAG system performance\"\"\"\n",
    "    \n",
    "    if not test_results:\n",
    "        print(\"No test results to analyze\")\n",
    "        return\n",
    "    \n",
    "    print(\"📊 RAG PERFORMANCE ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Timing analysis\n",
    "    retrieval_times = [r['performance']['retrieval_time'] for r in test_results]\n",
    "    generation_times = [r['performance']['generation_time'] for r in test_results]\n",
    "    total_times = [r['performance']['total_time'] for r in test_results]\n",
    "    \n",
    "    print(f\"\\n⏱️ TIMING METRICS:\")\n",
    "    print(f\"Average retrieval time: {np.mean(retrieval_times):.2f}s\")\n",
    "    print(f\"Average generation time: {np.mean(generation_times):.2f}s\")\n",
    "    print(f\"Average total time: {np.mean(total_times):.2f}s\")\n",
    "    \n",
    "    # Source diversity\n",
    "    all_sources = set()\n",
    "    for result in test_results:\n",
    "        all_sources.update(result['sources'])\n",
    "    \n",
    "    print(f\"\\n📚 SOURCE COVERAGE:\")\n",
    "    print(f\"Unique sources used: {len(all_sources)}\")\n",
    "    print(f\"Sources: {', '.join(all_sources)}\")\n",
    "    \n",
    "    # Chunk analysis\n",
    "    chunks_per_query = [r['performance']['chunks_retrieved'] for r in test_results]\n",
    "    print(f\"\\n🔍 RETRIEVAL METRICS:\")\n",
    "    print(f\"Average chunks per query: {np.mean(chunks_per_query):.1f}\")\n",
    "    print(f\"Retrieval consistency: {np.std(chunks_per_query):.1f} std dev\")\n",
    "    \n",
    "    # Answer length analysis\n",
    "    answer_lengths = [len(r['answer']) for r in test_results]\n",
    "    print(f\"\\n📝 ANSWER METRICS:\")\n",
    "    print(f\"Average answer length: {np.mean(answer_lengths):.0f} chars\")\n",
    "    print(f\"Answer length range: {min(answer_lengths)}-{max(answer_lengths)} chars\")\n",
    "\n",
    "# Analyze the test results\n",
    "analyze_rag_performance(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72e974e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Results saved to: ../data/vector_store/strategy1_chromadb_results.json\n",
      "\n",
      "🏆 STRATEGY 1 CHROMADB RAG - COMPLETE!\n",
      "==================================================\n",
      "✅ Vector database created and populated\n",
      "✅ Semantic search implemented\n",
      "✅ Answer generation working\n",
      "✅ Test questions processed\n",
      "✅ Performance metrics collected\n",
      "\n",
      "🎯 NEXT STEPS:\n",
      "1. Implement your optimizations in the workspace above\n",
      "2. Test with more complex academic questions\n",
      "3. Compare with Strategy 2 (Advanced RAG)\n",
      "4. Consider building a web interface with Streamlit\n",
      "\n",
      "💡 READY FOR OPTIMIZATION!\n",
      "Head to the optimization workspace and make this RAG system even better! 🚀\n"
     ]
    }
   ],
   "source": [
    "# 💾 SAVE RESULTS AND CONFIGURATION\n",
    "def save_rag_results(test_results: List[Dict[str, Any]], config: RAGConfig):\n",
    "    \"\"\"Save test results and configuration for comparison\"\"\"\n",
    "    \n",
    "    output_data = {\n",
    "        'strategy': 'ChromaDB Basic RAG',\n",
    "        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'configuration': {\n",
    "            'chunk_size': config.CHUNK_SIZE,\n",
    "            'chunk_overlap': config.CHUNK_OVERLAP,\n",
    "            'embedding_model': config.EMBEDDING_MODEL,\n",
    "            'retrieval_k': config.RETRIEVAL_K,\n",
    "            'llm_model': config.LLM_MODEL,\n",
    "            'llm_temperature': config.LLM_TEMPERATURE\n",
    "        },\n",
    "        'test_results': test_results,\n",
    "        'performance_summary': {\n",
    "            'total_questions': len(test_results),\n",
    "            'avg_retrieval_time': np.mean([r['performance']['retrieval_time'] for r in test_results]) if test_results else 0,\n",
    "            'avg_generation_time': np.mean([r['performance']['generation_time'] for r in test_results]) if test_results else 0,\n",
    "            'unique_sources': len(set().union(*[r['sources'] for r in test_results])) if test_results else 0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save to JSON file\n",
    "    output_file = os.path.join(config.OUTPUT_DIR, 'strategy1_chromadb_results.json')\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(output_data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"✅ Results saved to: {output_file}\")\n",
    "    return output_file\n",
    "\n",
    "# Save results\n",
    "if test_results:\n",
    "    save_rag_results(test_results, config)\n",
    "\n",
    "print(\"\\n🏆 STRATEGY 1 CHROMADB RAG - COMPLETE!\")\n",
    "print(\"=\"*50)\n",
    "print(\"✅ Vector database created and populated\")\n",
    "print(\"✅ Semantic search implemented\") \n",
    "print(\"✅ Answer generation working\")\n",
    "print(\"✅ Test questions processed\")\n",
    "print(\"✅ Performance metrics collected\")\n",
    "\n",
    "print(\"\\n🎯 NEXT STEPS:\")\n",
    "print(\"1. Implement your optimizations in the workspace above\")\n",
    "print(\"2. Test with more complex academic questions\")\n",
    "print(\"3. Compare with Strategy 2 (Advanced RAG)\")\n",
    "print(\"4. Consider building a web interface with Streamlit\")\n",
    "\n",
    "print(\"\\n💡 READY FOR OPTIMIZATION!\")\n",
    "print(\"Head to the optimization workspace and make this RAG system even better! 🚀\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
