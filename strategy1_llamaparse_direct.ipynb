{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "570cb3cb",
   "metadata": {},
   "source": [
    "# üéØ Strategy 1: Direct LlamaParse Approach\n",
    "\n",
    "**Philosophy**: Leverage LlamaParse's sophisticated built-in AI to directly convert PDFs into structured academic content.\n",
    "\n",
    "## Optimization Areas:\n",
    "- System prompt engineering for academic papers\n",
    "- Result type selection (text vs markdown)\n",
    "- API parameters tuning\n",
    "- Post-processing logic\n",
    "- Error handling improvements\n",
    "\n",
    "## Available Papers:\n",
    "- `30YearsResearchGate.pdf`\n",
    "- `SchenkBekkerSchmitt2025PrecRes.pdf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faee8540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: llama_parse in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (0.6.51)\n",
      "Requirement already satisfied: llama-cloud-services>=0.6.51 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama_parse) (0.6.51)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud-services>=0.6.51->llama_parse) (8.1.8)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud-services>=0.6.51->llama_parse) (0.2.2)\n",
      "Requirement already satisfied: llama-index-core>=0.12.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud-services>=0.6.51->llama_parse) (0.12.52)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud-services>=0.6.51->llama_parse) (1.1.1)\n",
      "Requirement already satisfied: llama-cloud==0.1.34 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud-services>=0.6.51->llama_parse) (0.1.34)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=4.3.7 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud-services>=0.6.51->llama_parse) (4.3.8)\n",
      "Requirement already satisfied: pydantic!=2.10,>=2.8 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud-services>=0.6.51->llama_parse) (2.11.7)\n",
      "Requirement already satisfied: tenacity<10.0,>=8.5.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud-services>=0.6.51->llama_parse) (9.1.2)\n",
      "Requirement already satisfied: llama_parse in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (0.6.51)\n",
      "Requirement already satisfied: llama-cloud-services>=0.6.51 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama_parse) (0.6.51)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud-services>=0.6.51->llama_parse) (8.1.8)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud-services>=0.6.51->llama_parse) (0.2.2)\n",
      "Requirement already satisfied: llama-index-core>=0.12.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud-services>=0.6.51->llama_parse) (0.12.52)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud-services>=0.6.51->llama_parse) (1.1.1)\n",
      "Requirement already satisfied: llama-cloud==0.1.34 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud-services>=0.6.51->llama_parse) (0.1.34)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=4.3.7 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud-services>=0.6.51->llama_parse) (4.3.8)\n",
      "Requirement already satisfied: pydantic!=2.10,>=2.8 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud-services>=0.6.51->llama_parse) (2.11.7)\n",
      "Requirement already satisfied: tenacity<10.0,>=8.5.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud-services>=0.6.51->llama_parse) (9.1.2)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud==0.1.34->llama-cloud-services>=0.6.51->llama_parse) (2025.7.14)\n",
      "Requirement already satisfied: httpx>=0.20.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud==0.1.34->llama-cloud-services>=0.6.51->llama_parse) (0.28.1)\n",
      "Requirement already satisfied: anyio in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from httpx>=0.20.0->llama-cloud==0.1.34->llama-cloud-services>=0.6.51->llama_parse) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from httpx>=0.20.0->llama-cloud==0.1.34->llama-cloud-services>=0.6.51->llama_parse) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from httpx>=0.20.0->llama-cloud==0.1.34->llama-cloud-services>=0.6.51->llama_parse) (3.10)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud==0.1.34->llama-cloud-services>=0.6.51->llama_parse) (2025.7.14)\n",
      "Requirement already satisfied: httpx>=0.20.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-cloud==0.1.34->llama-cloud-services>=0.6.51->llama_parse) (0.28.1)\n",
      "Requirement already satisfied: anyio in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from httpx>=0.20.0->llama-cloud==0.1.34->llama-cloud-services>=0.6.51->llama_parse) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from httpx>=0.20.0->llama-cloud==0.1.34->llama-cloud-services>=0.6.51->llama_parse) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from httpx>=0.20.0->llama-cloud==0.1.34->llama-cloud-services>=0.6.51->llama_parse) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx>=0.20.0->llama-cloud==0.1.34->llama-cloud-services>=0.6.51->llama_parse) (0.16.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (0.9.0)\n",
      "Requirement already satisfied: sqlalchemy[asyncio]>=1.4.49 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (2.0.41)\n",
      "Requirement already satisfied: dataclasses-json in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (0.6.7)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (80.9.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (4.67.1)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (3.2.1)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (2.32.4)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx>=0.20.0->llama-cloud==0.1.34->llama-cloud-services>=0.6.51->llama_parse) (0.16.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (0.9.0)\n",
      "Requirement already satisfied: sqlalchemy[asyncio]>=1.4.49 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (2.0.41)\n",
      "Requirement already satisfied: dataclasses-json in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (0.6.7)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (80.9.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (4.67.1)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (3.2.1)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (2.32.4)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.2.0)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.2.18)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.6.0)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (3.12.14)\n",
      "Requirement already satisfied: aiosqlite in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (0.21.0)\n",
      "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.1.0)\n",
      "Requirement already satisfied: numpy in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (2.0.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (4.14.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (3.9.1)\n",
      "Requirement already satisfied: banks<3,>=2.2.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (2.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (2025.7.0)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (11.3.0)\n",
      "Requirement already satisfied: wrapt in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.17.2)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.0.8)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.7.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (5.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (2.6.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (25.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (6.6.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.20.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (0.3.2)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.4.0)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.2.0)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.2.18)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.6.0)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (3.12.14)\n",
      "Requirement already satisfied: aiosqlite in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (0.21.0)\n",
      "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.1.0)\n",
      "Requirement already satisfied: numpy in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (2.0.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (4.14.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (3.9.1)\n",
      "Requirement already satisfied: banks<3,>=2.2.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (2.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (2025.7.0)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (11.3.0)\n",
      "Requirement already satisfied: wrapt in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.17.2)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.0.8)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.7.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (5.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (2.6.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (25.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (6.6.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.20.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (0.3.2)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.4.0)\n",
      "Requirement already satisfied: griffe in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from banks<3,>=2.2.0->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.8.0)\n",
      "Requirement already satisfied: jinja2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from banks<3,>=2.2.0->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (3.1.6)\n",
      "Requirement already satisfied: griffe in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from banks<3,>=2.2.0->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.8.0)\n",
      "Requirement already satisfied: jinja2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from banks<3,>=2.2.0->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (3.1.6)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (0.3.0)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (0.3.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from nltk>3.8.1->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (2024.11.6)\n",
      "Requirement already satisfied: joblib in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from nltk>3.8.1->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.5.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from pydantic!=2.10,>=2.8->llama-cloud-services>=0.6.51->llama_parse) (0.4.1)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from pydantic!=2.10,>=2.8->llama-cloud-services>=0.6.51->llama_parse) (2.33.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from pydantic!=2.10,>=2.8->llama-cloud-services>=0.6.51->llama_parse) (0.7.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from requests>=2.31.0->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (2.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from requests>=2.31.0->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (3.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from nltk>3.8.1->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (2024.11.6)\n",
      "Requirement already satisfied: joblib in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from nltk>3.8.1->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.5.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from pydantic!=2.10,>=2.8->llama-cloud-services>=0.6.51->llama_parse) (0.4.1)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from pydantic!=2.10,>=2.8->llama-cloud-services>=0.6.51->llama_parse) (2.33.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from pydantic!=2.10,>=2.8->llama-cloud-services>=0.6.51->llama_parse) (0.7.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from requests>=2.31.0->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (2.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from requests>=2.31.0->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (3.4.2)\n",
      "Requirement already satisfied: greenlet>=1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (3.2.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from typing-inspect>=0.8.0->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.1.0)\n",
      "Requirement already satisfied: greenlet>=1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (3.2.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from typing-inspect>=0.8.0->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (1.1.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from anyio->httpx>=0.20.0->llama-cloud==0.1.34->llama-cloud-services>=0.6.51->llama_parse) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from anyio->httpx>=0.20.0->llama-cloud==0.1.34->llama-cloud-services>=0.6.51->llama_parse) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from anyio->httpx>=0.20.0->llama-cloud==0.1.34->llama-cloud-services>=0.6.51->llama_parse) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from anyio->httpx>=0.20.0->llama-cloud==0.1.34->llama-cloud-services>=0.6.51->llama_parse) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from dataclasses-json->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (25.0)\n",
      "Requirement already satisfied: colorama>=0.4 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from griffe->banks<3,>=2.2.0->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (3.0.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from dataclasses-json->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (25.0)\n",
      "Requirement already satisfied: colorama>=0.4 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from griffe->banks<3,>=2.2.0->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/fredygerman/Library/Python/3.9/lib/python/site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core>=0.12.0->llama-cloud-services>=0.6.51->llama_parse) (3.0.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip3 install llama_parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09d8e2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fredygerman/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from llama_parse import LlamaParse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ca150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Keys\n",
    "api_key = \"llx-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5ebbc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö° OPTIMIZATION AREA 1: Custom System Prompt for Academic Papers\n",
    "# Try different prompts that emphasize specific academic elements\n",
    "parsing_instruction_research = \"\"\"\n",
    "The provided document is a research paper. I want you to parse it systematically while preserving the academic structure and important content.\n",
    "\n",
    "IMPORTANT PARSING GUIDELINES:\n",
    "1. Preserve academic sections: abstract, introduction, methodology, results, discussion, conclusion, references\n",
    "2. Maintain figure captions and table data as separate sections\n",
    "3. Extract section numbers (e.g., \"2.1\", \"3.2\") when available\n",
    "4. Preserve mathematical formulas, equations, and citations\n",
    "5. Filter out headers/footers but keep page numbers\n",
    "6. Maintain academic formatting and language\n",
    "7. Break content at logical academic boundaries (sections, subsections, paragraphs)\n",
    "\n",
    "The output should maintain the scholarly structure of the original document.\n",
    "\"\"\"\n",
    "\n",
    "# üîß TRY: Alternative prompt variations:\n",
    "\n",
    "# Option A: More specific academic focus\n",
    "# parsing_instruction_v2 = \"\"\"\n",
    "# You are an expert academic document parser specializing in research papers.\n",
    "# Focus on:\n",
    "# 1. Precise section identification (abstract, intro, methods, results, discussion, conclusion)\n",
    "# 2. Mathematical equation preservation\n",
    "# 3. Citation and reference handling\n",
    "# 4. Figure/table metadata extraction\n",
    "# Break into granular chunks maintaining academic integrity.\n",
    "# \"\"\"\n",
    "\n",
    "# Option B: Structure-first approach\n",
    "# parsing_instruction_v3 = \"\"\"\n",
    "# Parse this research paper with emphasis on structural hierarchy:\n",
    "# 1. Identify main sections and subsections\n",
    "# 2. Preserve numbering systems (1.1, 1.2, etc.)\n",
    "# 3. Separate visual elements (figures, tables, equations)\n",
    "# 4. Maintain citation context and reference links\n",
    "# Create logical, hierarchical chunks that preserve academic flow.\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7e75fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research paper file paths\n",
    "research_paper_1 = \"/Users/fredygerman/Personal/builds/exp/twiga-challenge-1/data/papers/30YearsResearchGate.pdf\"\n",
    "research_paper_2 = \"/Users/fredygerman/Personal/builds/exp/twiga-challenge-1/data/papers/SchenkBekkerSchmitt2025PrecRes.pdf\"\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"/Users/fredygerman/Personal/builds/exp/twiga-challenge-1/data/input_papers/\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d32ec1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_paper_with_llamaparse(input_file, output_file, custom_prompt=None):\n",
    "    \"\"\"Process a research paper using LlamaParse\"\"\"\n",
    "    \n",
    "    prompt = custom_prompt or parsing_instruction_research\n",
    "    \n",
    "    # ‚ö° OPTIMIZATION AREA 2: LlamaParse Parameters\n",
    "    # Experiment with different result_type, system_prompt combinations\n",
    "    parser = LlamaParse(\n",
    "        api_key=api_key,\n",
    "        result_type=\"markdown\",  # üîß TRY: \"text\", \"markdown\", or other formats\n",
    "        system_prompt=prompt,  # üîß TRY: Different prompt variations\n",
    "        verbose=True,\n",
    "        # üîß TRY: Add other parameters like language=\"en\", num_workers=4, etc.\n",
    "        # language=\"en\",\n",
    "        # num_workers=4,\n",
    "        # split_by_page=False,\n",
    "    )\n",
    "    \n",
    "    print(f\"Parsing research paper: {input_file}\")\n",
    "    parsed_document = parser.load_data(input_file)\n",
    "    \n",
    "    # ‚ö° OPTIMIZATION AREA 3: Post-processing Enhancement\n",
    "    # Add custom logic to improve parsing results\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for doc in parsed_document:\n",
    "            # üîß TRY: Add filtering, formatting, or enhancement logic here\n",
    "            content = doc.text\n",
    "            \n",
    "            # Example post-processing options:\n",
    "            # content = clean_academic_text(content)\n",
    "            # content = enhance_section_headers(content)\n",
    "            # content = fix_citations(content)\n",
    "            \n",
    "            f.write(content + '\\n')\n",
    "    \n",
    "    print(f\"Parsed content saved to: {output_file}\")\n",
    "    return parsed_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "762e23a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing research paper: /Users/fredygerman/Personal/builds/exp/twiga-challenge-1/data/papers/30YearsResearchGate.pdf\n",
      "Started parsing the file under job_id e6be10a1-ec8a-4ed4-94a0-4dda0cae4bd8\n",
      "Started parsing the file under job_id e6be10a1-ec8a-4ed4-94a0-4dda0cae4bd8\n",
      "Parsed content saved to: /Users/fredygerman/Personal/builds/exp/twiga-challenge-1/data/input_papers/strategy1_paper1_llamaparse.md\n",
      "Parsed content saved to: /Users/fredygerman/Personal/builds/exp/twiga-challenge-1/data/input_papers/strategy1_paper1_llamaparse.md\n"
     ]
    }
   ],
   "source": [
    "# Process first research paper\n",
    "output_file_1 = os.path.join(output_dir, \"strategy1_paper1_llamaparse.md\")\n",
    "parsed_doc_1 = process_paper_with_llamaparse(research_paper_1, output_file_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e85da77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing research paper: /Users/fredygerman/Personal/builds/exp/twiga-challenge-1/data/papers/SchenkBekkerSchmitt2025PrecRes.pdf\n",
      "Started parsing the file under job_id a7bcb89e-e3ac-43b8-8640-46b7f39ce032\n",
      "Started parsing the file under job_id a7bcb89e-e3ac-43b8-8640-46b7f39ce032\n",
      "..Parsed content saved to: /Users/fredygerman/Personal/builds/exp/twiga-challenge-1/data/input_papers/strategy1_paper2_llamaparse.md\n",
      "Parsed content saved to: /Users/fredygerman/Personal/builds/exp/twiga-challenge-1/data/input_papers/strategy1_paper2_llamaparse.md\n"
     ]
    }
   ],
   "source": [
    "# Process second research paper\n",
    "output_file_2 = os.path.join(output_dir, \"strategy1_paper2_llamaparse.md\")\n",
    "parsed_doc_2 = process_paper_with_llamaparse(research_paper_2, output_file_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50868c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä ANALYSIS RESULTS FOR Paper 1 (30YearsResearchGate):\n",
      "Total content length: 51,889 characters\n",
      "Total lines: 714\n",
      "Academic sections found: {'abstract': 24, 'introduction': 25, 'methodology': 30, 'results': 27, 'discussion': 29, 'conclusion': 30, 'references': 26}\n",
      "Figures mentioned: 46\n",
      "Tables mentioned: 26\n",
      "Potential citations: 193\n",
      "\n",
      "üìä ANALYSIS RESULTS FOR Paper 2 (SchenkBekkerSchmitt2025):\n",
      "Total content length: 69,657 characters\n",
      "Total lines: 785\n",
      "Academic sections found: {'abstract': 22, 'introduction': 22, 'methodology': 27, 'results': 27, 'discussion': 19, 'conclusion': 18, 'references': 21}\n",
      "Figures mentioned: 43\n",
      "Tables mentioned: 42\n",
      "Potential citations: 341\n"
     ]
    }
   ],
   "source": [
    "# ‚ö° OPTIMIZATION AREA 4: Quality Assessment and Comparison\n",
    "def analyze_parsing_results(output_file, paper_name):\n",
    "    \"\"\"Analyze the quality of parsing results\"\"\"\n",
    "    \n",
    "    with open(output_file, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Basic metrics\n",
    "    total_length = len(content)\n",
    "    line_count = len(content.split('\\n'))\n",
    "    \n",
    "    # Academic structure detection\n",
    "    sections = {\n",
    "        'abstract': content.lower().count('abstract'),\n",
    "        'introduction': content.lower().count('introduction'),\n",
    "        'methodology': content.lower().count('methodology') + content.lower().count('methods'),\n",
    "        'results': content.lower().count('results'),\n",
    "        'discussion': content.lower().count('discussion'),\n",
    "        'conclusion': content.lower().count('conclusion'),\n",
    "        'references': content.lower().count('references') + content.lower().count('bibliography')\n",
    "    }\n",
    "    \n",
    "    # Figure and table detection\n",
    "    figures = content.lower().count('figure')\n",
    "    tables = content.lower().count('table')\n",
    "    \n",
    "    # Citations (rough estimate)\n",
    "    citations = content.count('(') + content.count('[')\n",
    "    \n",
    "    print(f\"\\nüìä ANALYSIS RESULTS FOR {paper_name}:\")\n",
    "    print(f\"Total content length: {total_length:,} characters\")\n",
    "    print(f\"Total lines: {line_count:,}\")\n",
    "    print(f\"Academic sections found: {sections}\")\n",
    "    print(f\"Figures mentioned: {figures}\")\n",
    "    print(f\"Tables mentioned: {tables}\")\n",
    "    print(f\"Potential citations: {citations}\")\n",
    "    \n",
    "    return {\n",
    "        'length': total_length,\n",
    "        'lines': line_count,\n",
    "        'sections': sections,\n",
    "        'figures': figures,\n",
    "        'tables': tables,\n",
    "        'citations': citations\n",
    "    }\n",
    "\n",
    "# Analyze both papers\n",
    "results_1 = analyze_parsing_results(output_file_1, \"Paper 1 (30YearsResearchGate)\")\n",
    "results_2 = analyze_parsing_results(output_file_2, \"Paper 2 (SchenkBekkerSchmitt2025)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97df370d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Strategy 1 Optimization Workspace\n",
      "\n",
      "Optimization Areas for LlamaParse:\n",
      "‚òê Custom academic prompts\n",
      "‚òê Result type optimization (text/markdown/json)\n",
      "‚òê Parameter tuning (language, workers, etc.)\n",
      "‚òê Post-processing enhancements\n",
      "‚òê Quality validation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Your optimized implementation:\\noptimized_prompt = \"\"\"\\nYOUR_CUSTOM_ACADEMIC_PROMPT_HERE\\n\"\"\"\\n\\noptimized_parser = LlamaParse(\\n    api_key=api_key,\\n    result_type=\"YOUR_OPTIMAL_TYPE\",\\n    system_prompt=optimized_prompt,\\n    language=\"en\",\\n    num_workers=4,\\n    # Add other optimized parameters\\n)\\n\\n# Process both papers with optimizations\\n# Add quality assessment and comparison\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üéØ YOUR OPTIMIZATION WORKSPACE\n",
    "# Implement your Strategy 1 optimizations here\n",
    "\n",
    "print(\"üöÄ Strategy 1 Optimization Workspace\")\n",
    "print(\"\\nOptimization Areas for LlamaParse:\")\n",
    "print(\"‚òê Custom academic prompts\")\n",
    "print(\"‚òê Result type optimization (text/markdown/json)\")\n",
    "print(\"‚òê Parameter tuning (language, workers, etc.)\")\n",
    "print(\"‚òê Post-processing enhancements\")\n",
    "print(\"‚òê Quality validation\")\n",
    "\n",
    "# TODO: Add your optimized LlamaParse implementation here\n",
    "\n",
    "# Example optimization template:\n",
    "'''\n",
    "# Your optimized implementation:\n",
    "optimized_prompt = \"\"\"\n",
    "YOUR_CUSTOM_ACADEMIC_PROMPT_HERE\n",
    "\"\"\"\n",
    "\n",
    "optimized_parser = LlamaParse(\n",
    "    api_key=api_key,\n",
    "    result_type=\"YOUR_OPTIMAL_TYPE\",\n",
    "    system_prompt=optimized_prompt,\n",
    "    language=\"en\",\n",
    "    num_workers=4,\n",
    "    # Add other optimized parameters\n",
    ")\n",
    "\n",
    "# Process both papers with optimizations\n",
    "# Add quality assessment and comparison\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0a6d946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ STRATEGY 1: LLAMAPARSE DIRECT RESULTS\n",
      "==================================================\n",
      "\n",
      "Paper 1 Results:\n",
      "  Content Length: 51,889 chars\n",
      "  Academic Sections: 191\n",
      "  Figures/Tables: 72\n",
      "\n",
      "Paper 2 Results:\n",
      "  Content Length: 69,657 chars\n",
      "  Academic Sections: 156\n",
      "  Figures/Tables: 85\n",
      "\n",
      "üéØ Next Steps:\n",
      "1. Review the generated markdown files\n",
      "2. Implement your optimizations above\n",
      "3. Compare results with other strategies\n",
      "4. Document your improvements\n"
     ]
    }
   ],
   "source": [
    "# üìä STRATEGY 1 RESULTS SUMMARY\n",
    "print(\"üèÜ STRATEGY 1: LLAMAPARSE DIRECT RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\nPaper 1 Results:\")\n",
    "print(f\"  Content Length: {results_1['length']:,} chars\")\n",
    "print(f\"  Academic Sections: {sum(results_1['sections'].values())}\")\n",
    "print(f\"  Figures/Tables: {results_1['figures'] + results_1['tables']}\")\n",
    "\n",
    "print(f\"\\nPaper 2 Results:\")\n",
    "print(f\"  Content Length: {results_2['length']:,} chars\")\n",
    "print(f\"  Academic Sections: {sum(results_2['sections'].values())}\")\n",
    "print(f\"  Figures/Tables: {results_2['figures'] + results_2['tables']}\")\n",
    "\n",
    "print(\"\\nüéØ Next Steps:\")\n",
    "print(\"1. Review the generated markdown files\")\n",
    "print(\"2. Implement your optimizations above\")\n",
    "print(\"3. Compare results with other strategies\")\n",
    "print(\"4. Document your improvements\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
